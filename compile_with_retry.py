#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import argparse
import os
import re
import subprocess
import sys
import time
import shutil
from pathlib import Path
import glob
import hashlib

try:
    import requests
    from bs4 import BeautifulSoup
    LIBS_AVAILABLE = True
except ImportError:
    LIBS_AVAILABLE = False
    print("è­¦å‘Š: æœªå®‰è£… requests å’Œ beautifulsoup4ï¼Œlua-neturl ä¸‹è½½ä¿®å¤ä¸å¯ç”¨")

# OOM é«˜é£é™©åŒ…åˆ—è¡¨ï¼ˆæ¥è‡ªç‰ˆæœ¬ 2ï¼‰
OOM_PRONE_PACKAGE_PATTERNS = [
    r'/gcc-\d+', r'/llvm-\d+', r'/qt5base-\d+', r'/webkitgtk-\d+', r'/linux-\d+'
]

# é”™è¯¯ç­¾åæ£€æµ‹ï¼ˆç»“åˆç‰ˆæœ¬ 1 å’Œ 2ï¼‰
def get_error_signature(log_content):
    if not log_content: return "no_log_content"
    if re.search(r'Killed|signal 9|Error 137', log_content): return "oom_detected"
    if "undefined reference to" in log_content and "netifd" in log_content: return "netifd_link_error"
    if "missing separator" in log_content: return "makefile_separator"
    if "Patch failed" in log_content: return "patch_failed"
    if LIBS_AVAILABLE and "lua-neturl" in log_content and "Download failed" in log_content: return "lua_neturl_download"
    if "trojan-plus" in log_content and "buffer-cast" in log_content: return "trojan_plus_buffer_cast"
    if "mkdir: cannot create directory" in log_content: return "directory_conflict"
    if "ln: failed to create symbolic link" in log_content: return "symlink_conflict"
    if "toolchain" in log_content and "provides" in log_content: return "toolchain_provides_syntax"
    if "luci-lib-taskd" in log_content: return "luci_lib_taskd_depends"
    if "base-files=" in log_content and "Error 99" in log_content: return "apk_add_base_files"
    return "unknown_error"

# OOM å¤„ç†ï¼ˆç»“åˆç‰ˆæœ¬ 1 å’Œ 2ï¼‰
def handle_oom(current_jobs, log_content):
    for pattern in OOM_PRONE_PACKAGE_PATTERNS:
        if re.search(pattern, log_content):
            print("æ£€æµ‹åˆ° OOM é«˜é£é™©åŒ…ï¼Œå¼ºåˆ¶ä½¿ç”¨ -j1")
            return 1
    return max(1, current_jobs // 2)  # ç‰ˆæœ¬ 1 çš„å‡åŠç­–ç•¥
def get_relative_path(path):
    """è·å–ç›¸å¯¹è·¯å¾„"""
    current_pwd = os.getcwd()

    if not os.path.isabs(path):
        # Try resolving relative to current dir first
        abs_path = os.path.abspath(path)
        if os.path.exists(abs_path):
            path = abs_path
        else:
            # If not found relative to cwd, return original path maybe it's inside build context
             return path

    try:
        # Check if path is inside current_pwd before making relative
        if Path(path).is_relative_to(current_pwd):
             return os.path.relpath(path, current_pwd)
        else:
            # If path is outside current working dir, return absolute path
            return path
    except ValueError: # Handle cases like different drives on Windows
        return path
    except Exception: # Generic fallback
        return path

# --- Fix Functions ---

def fix_netifd_libnl_tiny():
    """å¢å¼ºç‰ˆï¼šä¿®å¤ netifd ç¼–è¯‘æ—¶ç¼ºå°‘ libnl-tiny çš„é“¾æ¥é—®é¢˜"""
    import glob

    print("ğŸ”§ æ­£åœ¨å°è¯•ä¿®å¤ netifd ç¼ºå°‘ libnl-tiny çš„é“¾æ¥é”™è¯¯...")
    fixed = False

    try:
        # --- å¼ºåˆ¶æ¸…ç† ---
        print("ğŸ§¹ å¼ºåˆ¶æ¸…ç† libnl-tiny å’Œ netifd...")
        subprocess.run(["make", "package/libs/libnl-tiny/clean", "V=s"], check=False, capture_output=True)
        subprocess.run(["make", "package/network/config/netifd/clean", "V=s"], check=False, capture_output=True)
        # æ¸…ç† netifd çš„ CMake ç¼“å­˜ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        cmake_cache_files = glob.glob("build_dir/target-*/netifd-*/CMakeCache.txt")
        for cache_file in cmake_cache_files:
            print(f"ğŸ—‘ï¸ åˆ é™¤ CMake ç¼“å­˜: {cache_file}")
            try:
                os.remove(cache_file)
            except OSError as e:
                print(f"è­¦å‘Š: åˆ é™¤ CMake ç¼“å­˜å¤±è´¥: {e}")


        # --- é‡æ–°ç¼–è¯‘ libnl-tiny ---
        print("ğŸ”¨ ç¼–è¯‘ libnl-tiny...")
        compile_result = subprocess.run(["make", "package/libs/libnl-tiny/compile", "V=s"], check=False, capture_output=True, text=True)
        if compile_result.returncode != 0:
            print(f"âŒ libnl-tiny ç¼–è¯‘å¤±è´¥:\n{compile_result.stderr[-500:]}")
            # return False # ä¸è¦ç«‹å³è¿”å›ï¼Œç»§ç»­å°è¯•ä¿®æ”¹ netifd

        print("ğŸ“¦ å®‰è£… libnl-tiny...")
        install_result = subprocess.run(["make", "package/libs/libnl-tiny/install", "V=s"], check=False, capture_output=True, text=True)
        if install_result.returncode != 0:
            print(f"âŒ libnl-tiny å®‰è£…å¤±è´¥:\n{install_result.stderr[-500:]}")
            # return False

        # --- ç¡®è®¤ libnl-tiny åº“æ–‡ä»¶ ---
        lib_paths = glob.glob("staging_dir/target-*/usr/lib/libnl-tiny.so") # ä¼˜å…ˆæ£€æŸ¥ .so
        if not lib_paths:
             lib_paths = glob.glob("staging_dir/target-*/usr/lib/libnl-tiny.a") # æ£€æŸ¥ .a
        if not lib_paths:
            print("âŒ æœªæ‰¾åˆ° libnl-tiny çš„åº“æ–‡ä»¶ (libnl-tiny.so æˆ– libnl-tiny.a)ï¼Œä¿®å¤å¯èƒ½æ— æ•ˆã€‚")
            # return False # å³ä½¿æ‰¾ä¸åˆ°ä¹Ÿå¯èƒ½é€šè¿‡åç»­æ­¥éª¤ä¿®å¤
        else:
            print(f"âœ… æ‰¾åˆ° libnl-tiny åº“æ–‡ä»¶: {lib_paths[0]}")

        # --- ä¿®æ”¹ netifd çš„ Makefile ---
        netifd_makefile = Path("package/network/config/netifd/Makefile")
        if netifd_makefile.exists():
            print(f"ğŸ”§ æ£€æŸ¥å¹¶ä¿®æ”¹ {netifd_makefile}...")
            content_changed = False
            with open(netifd_makefile, "r", encoding="utf-8") as f:
                lines = f.readlines()

            new_lines = []
            depends_found = False
            ldflags_found = False
            for line in lines:
                if line.strip().startswith("DEPENDS:="):
                    depends_found = True
                    if "+libnl-tiny" not in line:
                        print("  â• æ·»åŠ  +libnl-tiny åˆ° DEPENDS")
                        line = line.rstrip() + " +libnl-tiny\n"
                        content_changed = True
                elif line.strip().startswith("TARGET_LDFLAGS +="):
                     ldflags_found = True
                     if "-lnl-tiny" not in line:
                         print("  â• æ·»åŠ  -lnl-tiny åˆ° TARGET_LDFLAGS")
                         line = line.rstrip() + " -lnl-tiny\n"
                         content_changed = True
                new_lines.append(line)

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ° TARGET_LDFLAGSï¼Œåˆ™åœ¨ PKG_BUILD_DEPENDS åæ·»åŠ 
            if not ldflags_found:
                 try:
                     insert_index = next(i for i, line in enumerate(new_lines) if line.strip().startswith('PKG_BUILD_DEPENDS:=')) + 1
                     print("  â• æ·»åŠ  TARGET_LDFLAGS += -lnl-tiny")
                     new_lines.insert(insert_index, 'TARGET_LDFLAGS += -lnl-tiny\n')
                     content_changed = True
                 except StopIteration:
                     print("  âš ï¸ æœªæ‰¾åˆ° PKG_BUILD_DEPENDSï¼Œæ— æ³•è‡ªåŠ¨æ·»åŠ  TARGET_LDFLAGS")


            if content_changed:
                with open(netifd_makefile, "w", encoding="utf-8") as f:
                    f.writelines(new_lines)
                print(f"âœ… å·²ä¿®æ”¹ {netifd_makefile}")
                fixed = True
            else:
                print(f"â„¹ï¸ {netifd_makefile} æ— éœ€ä¿®æ”¹ã€‚")
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ° {netifd_makefile}")

        # --- ä¿®æ”¹ netifd çš„ CMakeLists.txt (ä½œä¸ºè¡¥å……) ---
        # CMake é€šå¸¸ä¼šé€šè¿‡ DEPENDS è‡ªåŠ¨æ‰¾åˆ°åº“ï¼Œä½†ä»¥é˜²ä¸‡ä¸€
        cmake_path = Path("package/network/config/netifd/CMakeLists.txt")
        if cmake_path.exists():
            print(f"ğŸ”§ æ£€æŸ¥å¹¶ä¿®æ”¹ {cmake_path}...")
            content_changed = False
            with open(cmake_path, "r", encoding="utf-8") as f:
                content = f.read()

            # æŸ¥æ‰¾ target_link_libraries(netifd ...)
            link_match = re.search(r"target_link_libraries\s*\(\s*netifd\s+([^\)]+)\)", content, re.IGNORECASE)
            if link_match:
                linked_libs = link_match.group(1)
                if 'nl-tiny' not in linked_libs and 'libnl-tiny' not in linked_libs:
                    print("  â• æ·»åŠ  nl-tiny åˆ° target_link_libraries")
                    new_content = content.replace(
                        link_match.group(0),
                        f"target_link_libraries(netifd nl-tiny {linked_libs.strip()})"
                    )
                    content_changed = True
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•åœ¨ add_executable åæ·»åŠ 
            elif "add_executable(netifd" in content and "target_link_libraries(netifd" not in content:
                 print("  â• æ·»åŠ æ–°çš„ target_link_libraries(netifd nl-tiny ...)")
                 # å°è¯•æ‰¾åˆ°å·²æœ‰çš„åº“ä¾èµ–ï¼ˆé€šå¸¸æ˜¯ ubox, ubus ç­‰ï¼‰
                 existing_libs = []
                 find_lib_matches = re.findall(r"find_package\(([^ ]+)\s+REQUIRED\)", content)
                 if find_lib_matches:
                     existing_libs = [f"${{{lib.upper()}_LIBRARIES}}" for lib in find_lib_matches]
                 # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°±ç”¨å·²çŸ¥çš„åŸºç¡€åº“
                 if not existing_libs:
                     existing_libs = ["${UBOX_LIBRARIES}", "${UBUS_LIBRARIES}", "${UCI_LIBRARIES}", "${JSONC_LIBRARIES}", "${BLOBMSG_JSON_LIBRARIES}"] # å¯èƒ½éœ€è¦è°ƒæ•´

                 new_content = re.sub(
                     r"(add_executable\(netifd[^\)]+\))",
                     r"\1\ntarget_link_libraries(netifd nl-tiny " + " ".join(existing_libs) + ")",
                     content,
                     count=1
                 )
                 content_changed = True


            if content_changed:
                with open(cmake_path, "w", encoding="utf-8") as f:
                    f.write(new_content)
                print(f"âœ… å·²ä¿®æ”¹ {cmake_path}")
                fixed = True
            else:
                print(f"â„¹ï¸ {cmake_path} æ— éœ€ä¿®æ”¹ã€‚")
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ° {cmake_path}")


        # --- å†æ¬¡æ¸…ç† netifd ä»¥ç¡®ä¿æ›´æ”¹ç”Ÿæ•ˆ ---
        if fixed:
            print("ğŸ§¹ å†æ¬¡æ¸…ç† netifd ä»¥åº”ç”¨æ›´æ”¹...")
            subprocess.run(["make", "package/network/config/netifd/clean", "V=s"], check=False, capture_output=True)

        print("âœ… netifd å’Œ libnl-tiny ä¿®å¤æµç¨‹å®Œæˆã€‚")
        # å³ä½¿æ²¡æœ‰æ˜ç¡®ä¿®æ”¹æ–‡ä»¶ï¼Œä¹Ÿè¿”å› Trueï¼Œå› ä¸ºæ¸…ç†å’Œé‡æ–°ç¼–è¯‘æœ¬èº«å°±æ˜¯ä¸€ç§ä¿®å¤å°è¯•
        return True

    except Exception as e:
        print(f"âŒ ä¿®å¤ netifd/libnl-tiny æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
        return False
def fix_trojan_plus_issues():
    """ä¿®å¤ trojan-plus ç›¸å…³çš„ç¼–è¯‘é—®é¢˜"""
    print("ğŸ”§ æ£€æµ‹åˆ° trojan-plus ç›¸å…³é”™è¯¯ï¼Œå°è¯•ç¦ç”¨...")
    makefile_paths = list(Path(".").glob("**/luci-app-passwall/Makefile"))
    fixed_any = False
    for makefile_path in makefile_paths:
        try:
            print(f"æ£€æŸ¥: {makefile_path}")
            with open(makefile_path, "r", encoding="utf-8", errors="replace") as f:
                content = f.read()
            original_content = content

            # ç¦ç”¨ select PACKAGE_trojan-plus
            content = re.sub(r'^\s*\+\s*PACKAGE_trojan-plus\s*.*?\n', '', content, flags=re.MULTILINE)
            # ç¦ç”¨ default y for Trojan_Plus include
            content = re.sub(r'(config PACKAGE_.*?_INCLUDE_Trojan_Plus\s*\n(?:.*\n)*?\s*default )\s*y', r'\1n', content)

            if content != original_content:
                with open(makefile_path, "w", encoding="utf-8") as f:
                    f.write(content)
                print(f"âœ… å·²ä¿®æ”¹ {makefile_path}")
                fixed_any = True
            else:
                print(f"â„¹ï¸ {makefile_path} æ— éœ€ä¿®æ”¹ã€‚")

        except Exception as e:
            print(f"âŒ å¤„ç† {makefile_path} æ—¶å‡ºé”™: {e}")

    if fixed_any:
        # æ¸…ç† trojan-plus åŒ…ä»¥ç¡®ä¿ä¿®æ”¹ç”Ÿæ•ˆ
        print("ğŸ§¹ æ¸…ç† trojan-plus ç›¸å…³åŒ…...")
        # Find the package path dynamically
        trojan_plus_paths = list(Path(".").glob("**/trojan-plus/Makefile"))
        for tp_path in trojan_plus_paths:
            pkg_path = tp_path.parent.relative_to(Path.cwd())
            clean_cmd = ["make", f"{pkg_path}/clean", "V=s"]
            print(f"è¿è¡Œ: {' '.join(clean_cmd)}")
            subprocess.run(clean_cmd, check=False, capture_output=True)
        return True
    else:
        print("â„¹ï¸ æœªæ‰¾åˆ°éœ€è¦ä¿®å¤çš„ trojan-plus ç›¸å…³ Makefileã€‚")
        return False


def fix_lua_neturl_directory():
    """ä¿®å¤ lua-neturl çš„ Makefile å’Œè¡¥ä¸"""
    print("ğŸ”§ ä¿®å¤ lua-neturl Makefile å’Œè¡¥ä¸...")
    makefile_path_pattern = "**/lua-neturl/Makefile"
    makefile_paths = list(Path(".").glob(makefile_path_pattern))

    if not makefile_paths:
        print("âŒ æ— æ³•æ‰¾åˆ° lua-neturl çš„ Makefile")
        return False

    makefile_path = makefile_paths[0] # Assume first found is the correct one
    patch_dir = makefile_path.parent / "patches"
    print(f"æ‰¾åˆ° Makefile: {makefile_path}")
    modified = False

    try:
        with open(makefile_path, 'r', encoding='utf-8', errors='replace') as f:
            content = f.read()
        original_content = content

        # ç¡®ä¿ PKG_BUILD_DIR æ­£ç¡®
        pkg_source_match = re.search(r'^\s*PKG_SOURCE:=([^\n]+)', content, re.MULTILINE)
        pkg_version_match = re.search(r'^\s*PKG_VERSION:=([^\n]+)', content, re.MULTILINE)
        pkg_release_match = re.search(r'^\s*PKG_RELEASE:=([^\n]+)', content, re.MULTILINE)

        if pkg_source_match and pkg_version_match:
            pkg_source = pkg_source_match.group(1).strip()
            pkg_version = pkg_version_match.group(1).strip()
            pkg_release = pkg_release_match.group(1).strip() if pkg_release_match else "1"

            # Derive expected dir name, e.g., neturl-1.2 or neturl-v1.2-1
            # Try common patterns
            expected_subdir = f"neturl-{pkg_version}"
            if pkg_release and pkg_release != "1":
                 expected_subdir += f"-{pkg_release}" # Less common but possible

            # More robust: look at PKG_SOURCE name pattern like neturl-xxx.tar.gz
            source_base = Path(pkg_source).stem
            if source_base.endswith('.tar'): # Handle .tar.gz etc.
                source_base = Path(source_base).stem
            if source_base.startswith("neturl-"):
                expected_subdir = source_base
            elif source_base.startswith("v"): # Handle tags like v1.2-1
                 expected_subdir = f"neturl-{source_base.lstrip('v')}"


            build_dir_line = f"PKG_BUILD_DIR:=$(BUILD_DIR)/{expected_subdir}"
            build_dir_regex = r'^\s*PKG_BUILD_DIR:=\$\(BUILD_DIR\)/.*'

            if not re.search(build_dir_regex, content, re.MULTILINE):
                # Insert after PKG_SOURCE_URL or PKG_HASH
                insert_after = r'^\s*PKG_HASH:=[^\n]+'
                if not re.search(insert_after, content, re.MULTILINE):
                    insert_after = r'^\s*PKG_SOURCE_URL:=[^\n]+'
                if not re.search(insert_after, content, re.MULTILINE):
                     insert_after = r'^\s*PKG_RELEASE:=[^\n]+' # Fallback

                if re.search(insert_after, content, re.MULTILINE):
                     content = re.sub(f'({insert_after})', f'\\1\n{build_dir_line}', content, 1, re.MULTILINE)
                     print(f"âœ… æ·»åŠ  PKG_BUILD_DIR: {build_dir_line}")
                     modified = True
                else:
                     print("âš ï¸ æ— æ³•æ‰¾åˆ°åˆé€‚çš„æ’å…¥ç‚¹æ¥æ·»åŠ  PKG_BUILD_DIR")

            elif not re.search(r'^\s*PKG_BUILD_DIR:=\$\(BUILD_DIR\)/' + re.escape(expected_subdir) + r'\s*$', content, re.MULTILINE):
                 content = re.sub(build_dir_regex, build_dir_line, content, 1, re.MULTILINE)
                 print(f"âœ… ä¿®æ­£ PKG_BUILD_DIR ä¸º: {build_dir_line}")
                 modified = True

        else:
            print("âš ï¸ æ— æ³•ä» Makefile ä¸­æå– PKG_SOURCE æˆ– PKG_VERSIONã€‚")

        if content != original_content:
            with open(makefile_path, 'w', encoding='utf-8') as f:
                f.write(content)

        # å¤„ç†è¡¥ä¸ç›®å½• (éš”ç¦»é .patch æ–‡ä»¶)
        if patch_dir.exists() and patch_dir.is_dir():
            excluded_dir = patch_dir / "excluded"
            excluded_dir.mkdir(exist_ok=True)
            for item in patch_dir.iterdir():
                if item.is_file() and not item.name.endswith('.patch') and item.name != "excluded":
                    try:
                        dest = excluded_dir / item.name
                        shutil.move(str(item), str(dest))
                        print(f"âœ… å·²éš”ç¦»æ— æ•ˆè¡¥ä¸æ–‡ä»¶: {item.name} -> excluded/")
                        modified = True
                    except Exception as e:
                        print(f"âŒ éš”ç¦»æ–‡ä»¶ {item.name} å¤±è´¥: {e}")

    except Exception as e:
        print(f"âŒ å¤„ç† lua-neturl Makefile æ—¶å‡ºé”™: {e}")
        return False

    if modified:
        print("âœ… å·²å®Œæˆ lua-neturl çš„ Makefile å’Œè¡¥ä¸ä¿®å¤ã€‚")
        # Clean the package to apply changes
        pkg_rel_path = makefile_path.parent.relative_to(Path.cwd())
        subprocess.run(["make", f"{pkg_rel_path}/clean", "V=s"], check=False, capture_output=True)
        return True
    else:
        print("â„¹ï¸ lua-neturl æ— éœ€ä¿®å¤ã€‚")
        return False


def fix_patch_application(log_content):
    """ä¿®å¤è¡¥ä¸åº”ç”¨å¤±è´¥çš„é—®é¢˜"""
    print("ğŸ”§ æ£€æµ‹åˆ°è¡¥ä¸åº”ç”¨å¤±è´¥ï¼Œå°è¯•ä¿®å¤...")

    patch_failed_regex = r'Applying (.*?)(?: to .*)? using plaintext.*\n(?:.*\n){0,5}?(?:patch unexpectedly ends|Only garbage found|can\'t find file to patch|Hunk #\d+ FAILED)'
    patch_match = re.search(patch_failed_regex, log_content, re.MULTILINE)

    if not patch_match:
        print("â„¹ï¸ æœªæ˜ç¡®åŒ¹é…åˆ°è¡¥ä¸å¤±è´¥æ—¥å¿—ã€‚")
        return False

    patch_file = patch_match.group(1).strip()
    patch_file_path = Path(patch_file)
    print(f"è¯†åˆ«åˆ°å¯èƒ½å¤±è´¥çš„è¡¥ä¸æ–‡ä»¶: {patch_file}")

    if not patch_file_path.exists():
         # Try to find it relative to CWD if it's not absolute
         patch_file_path = Path.cwd() / patch_file
         if not patch_file_path.exists():
             print(f"âŒ è¡¥ä¸æ–‡ä»¶ {patch_file} æœªæ‰¾åˆ°ï¼Œæ— æ³•ä¿®å¤ã€‚")
             return False

    # Specific fix for lua-neturl patch issues
    if "lua-neturl" in str(patch_file_path):
        print("æ£€æµ‹åˆ° lua-neturl è¡¥ä¸å¤±è´¥ï¼Œè°ƒç”¨ä¸“ç”¨ä¿®å¤å‡½æ•°...")
        return fix_lua_neturl_directory() # This function handles both Makefile and patches

    # General fix: try removing the problematic patch
    print(f"è¡¥ä¸åº”ç”¨å¤±è´¥ï¼Œå°è¯•ç§»é™¤è¡¥ä¸æ–‡ä»¶: {patch_file_path}")
    try:
        # Backup first
        backup_path = patch_file_path.with_suffix(patch_file_path.suffix + ".disabled")
        shutil.move(str(patch_file_path), str(backup_path))
        print(f"âœ… å·²ç¦ç”¨è¡¥ä¸æ–‡ä»¶ (é‡å‘½åä¸º {backup_path.name})ã€‚")

        # Attempt to clean the package the patch belongs to
        # Try to guess package path from patch path (e.g., feeds/xxx/pkg/patches/ -> feeds/xxx/pkg)
        try:
            pkg_dir = patch_file_path.parent.parent # Go up from /patches
            if pkg_dir.exists() and (pkg_dir / "Makefile").exists():
                 pkg_rel_path = pkg_dir.relative_to(Path.cwd())
                 print(f"ğŸ§¹ å°è¯•æ¸…ç†ç›¸å…³åŒ…: {pkg_rel_path}")
                 subprocess.run(["make", f"{pkg_rel_path}/clean", "V=s"], check=False, capture_output=True)
            else:
                 print("âš ï¸ æ— æ³•ç¡®å®šè¡¥ä¸æ‰€å±åŒ…ç›®å½•ï¼Œè·³è¿‡æ¸…ç†ã€‚")
        except Exception as clean_e:
            print(f"âš ï¸ æ¸…ç†åŒ…æ—¶å‡ºé”™: {clean_e}")

        return True
    except Exception as e:
        print(f"âŒ ç¦ç”¨è¡¥ä¸ {patch_file_path} å¤±è´¥: {e}")
        return False


def fix_makefile_separator(log_content):
    """ä¿®å¤ Makefile "missing separator" é”™è¯¯"""
    print("ğŸ”§ æ£€æµ‹åˆ° 'missing separator' é”™è¯¯ï¼Œå°è¯•ä¿®å¤...")
    fixed = False

    # Regex to find the error line and capture file and line number
    # Handle variations like "Makefile:123: *** missing separator. Stop." or "common.mk:45: *** missing separator."
    error_line_match = re.search(r'^([\/\w\.\-]+):(\d+):\s+\*\*\*\s+missing separator', log_content, re.MULTILINE)

    if not error_line_match:
        print("âš ï¸ æ— æ³•ä»æ—¥å¿—ä¸­ç²¾ç¡®æå–æ–‡ä»¶åå’Œè¡Œå·ã€‚")
        return False

    makefile_name_from_err = error_line_match.group(1)
    line_num = int(error_line_match.group(2))
    print(f"è¯†åˆ«åˆ°é”™è¯¯ä½ç½®: æ–‡ä»¶='{makefile_name_from_err}', è¡Œå·={line_num}")

    # Try to find the context directory from "make[X]: Entering directory ..." lines above the error
    log_lines = log_content.splitlines()
    error_line_index = -1
    for i, line in enumerate(log_lines):
        if error_line_match.group(0) in line:
            error_line_index = i
            break

    context_dir = Path.cwd() # Default to current dir
    if error_line_index != -1:
        for i in range(error_line_index - 1, max(0, error_line_index - 50), -1):
            dir_match = re.search(r"make\[\d+\]: Entering directory '([^']+)'", log_lines[i])
            if dir_match:
                context_dir = Path(dir_match.group(1))
                print(f"æ‰¾åˆ°ä¸Šä¸‹æ–‡ç›®å½•: {context_dir}")
                break

    makefile_path = context_dir / makefile_name_from_err
    makefile_path_rel = get_relative_path(str(makefile_path)) # For display

    print(f"å°è¯•ä¿®å¤æ–‡ä»¶: {makefile_path_rel} (ç»å¯¹è·¯å¾„: {makefile_path})")

    if makefile_path.is_file():
        try:
            with open(makefile_path, 'r', encoding='utf-8', errors='replace') as f:
                makefile_lines = f.readlines()

            if 0 < line_num <= len(makefile_lines):
                line_content = makefile_lines[line_num - 1]
                original_line = line_content

                # Check if the line starts with spaces but not a tab
                if re.match(r'^[ ]+', line_content) and not line_content.startswith('\t'):
                    print(f"æ£€æµ‹åˆ°ç¬¬ {line_num} è¡Œä½¿ç”¨ç©ºæ ¼ç¼©è¿›ï¼Œæ›¿æ¢ä¸º TAB...")
                    # Backup the file
                    backup_path = makefile_path.with_suffix(makefile_path.suffix + ".bak")
                    shutil.copy2(makefile_path, backup_path)
                    print(f"åˆ›å»ºå¤‡ä»½: {get_relative_path(str(backup_path))}")

                    # Replace leading spaces with a tab
                    makefile_lines[line_num - 1] = '\t' + line_content.lstrip(' ')

                    with open(makefile_path, 'w', encoding='utf-8') as f:
                        f.writelines(makefile_lines)

                    # Verify fix
                    with open(makefile_path, 'r', encoding='utf-8', errors='replace') as f_check:
                         fixed_lines = f_check.readlines()
                    if fixed_lines[line_num - 1].startswith('\t'):
                         print(f"âœ… æˆåŠŸä¿®å¤ç¬¬ {line_num} è¡Œç¼©è¿›ã€‚")
                         fixed = True
                         os.remove(backup_path) # Remove backup on success
                    else:
                         print(f"âŒ ä¿®å¤å¤±è´¥ï¼Œç¬¬ {line_num} è¡Œå†…å®¹ä»ä¸º: '{fixed_lines[line_num-1].rstrip()}'")
                         shutil.move(str(backup_path), makefile_path) # Restore backup
                         print("å·²æ¢å¤å¤‡ä»½ã€‚")

                # Handle cases where the error might be on an empty line with weird whitespace
                elif not line_content.strip() and line_content != '\n':
                     print(f"ç¬¬ {line_num} è¡Œä¸ºéæ ‡å‡†ç©ºè¡Œï¼Œå°è¯•è§„èŒƒåŒ–ä¸ºç©ºè¡Œ...")
                     backup_path = makefile_path.with_suffix(makefile_path.suffix + ".bak")
                     shutil.copy2(makefile_path, backup_path)
                     makefile_lines[line_num - 1] = '\n'
                     with open(makefile_path, 'w', encoding='utf-8') as f:
                         f.writelines(makefile_lines)
                     print("âœ… å·²è§„èŒƒåŒ–ç©ºè¡Œã€‚")
                     fixed = True
                     os.remove(backup_path)

                else:
                    print(f"â„¹ï¸ ç¬¬ {line_num} è¡Œå†…å®¹: '{line_content.rstrip()}'ã€‚çœ‹èµ·æ¥ä¸æ˜¯ç®€å•çš„ç©ºæ ¼ç¼©è¿›é—®é¢˜ï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨æ£€æŸ¥æˆ–é—®é¢˜åœ¨ include çš„æ–‡ä»¶ä¸­ã€‚")
                    # Consider checking includes here if necessary, but keep it simple first.

            else:
                print(f"âŒ è¡Œå· {line_num} è¶…å‡ºæ–‡ä»¶ {makefile_path_rel} çš„èŒƒå›´ ({len(makefile_lines)} è¡Œ)ã€‚")

        except Exception as e:
            print(f"âŒ è¯»å†™æ–‡ä»¶ {makefile_path_rel} æ—¶å‡ºé”™: {e}")

    else:
        print(f"âŒ æ–‡ä»¶ '{makefile_path_rel}' ä¸å­˜åœ¨æˆ–ä¸æ˜¯æ–‡ä»¶ã€‚")

    # If a fix was attempted or the error persists, try cleaning the package directory
    if fixed or not fixed: # Always try cleaning if separator error occurred
        pkg_dir = makefile_path.parent
        # Heuristic: Check if the parent dir looks like a package dir
        if pkg_dir.exists() and (pkg_dir / "Makefile").exists() and pkg_dir != Path.cwd():
            pkg_rel_path = get_relative_path(str(pkg_dir))
            print(f"ğŸ§¹ å°è¯•æ¸…ç†ç›¸å…³åŒ…ç›®å½•: {pkg_rel_path}...")
            try:
                # Use DIRCLEAN=1 for a deeper clean
                subprocess.run(["make", f"{pkg_rel_path}/clean", "DIRCLEAN=1", "V=s"], check=False, capture_output=True)
                print(f"âœ… æ¸…ç†å‘½ä»¤å·²æ‰§è¡Œ (ä¸ä¿è¯æˆåŠŸ)ã€‚")
                # Setting fixed to True here means we *attempted* a fix (either edit or clean)
                fixed = True # Indicate an action was taken for this error
            except Exception as e:
                print(f"âš ï¸ æ‰§è¡Œæ¸…ç†å‘½ä»¤æ—¶å‡ºé”™: {e}")
        elif makefile_path.name == "Makefile" and context_dir == Path.cwd():
             print(f"ğŸ§¹ é”™è¯¯å‘ç”Ÿåœ¨æ ¹ Makefileï¼Œå°è¯•æ‰§è¡Œ 'make clean'... (è¿™å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´)")
             try:
                 subprocess.run(["make", "clean", "V=s"], check=False, capture_output=True)
                 print(f"âœ… 'make clean' å‘½ä»¤å·²æ‰§è¡Œã€‚")
                 fixed = True
             except Exception as e:
                 print(f"âš ï¸ æ‰§è¡Œ 'make clean' æ—¶å‡ºé”™: {e}")

    return fixed


def fix_directory_conflict(log_content):
    """ä¿®å¤ç›®å½•å†²çª (mkdir: cannot create directory ...: File exists)"""
    print("ğŸ”§ æ£€æµ‹åˆ°ç›®å½•å†²çªï¼Œå°è¯•ä¿®å¤...")
    conflict_match = re.search(r'mkdir: cannot create directory [\'"]?([^\'"]+)[\'"]?: File exists', log_content)
    if not conflict_match:
        print("â„¹ï¸ æœªåŒ¹é…åˆ° 'File exists' ç›®å½•å†²çªæ—¥å¿—ã€‚")
        return False

    conflict_path_str = conflict_match.group(1).strip()
    conflict_path = Path(conflict_path_str)
    print(f"å†²çªè·¯å¾„: {conflict_path}")

    # Important safety check: Avoid deleting critical directories
    critical_dirs = [Path.cwd(), Path.home(), Path("/"), Path("~"), Path("."), Path("..")]
    if conflict_path.resolve() in [p.resolve() for p in critical_dirs] or not conflict_path_str:
        print(f"âŒ æ£€æµ‹åˆ°å…³é”®ç›®å½•æˆ–æ— æ•ˆè·¯å¾„ ({conflict_path_str})ï¼Œæ‹’ç»åˆ é™¤ï¼")
        return False

    # Check if it's a file or a directory
    if conflict_path.is_file():
        print(f"å†²çªè·¯å¾„æ˜¯ä¸€ä¸ªæ–‡ä»¶ï¼Œå°è¯•åˆ é™¤æ–‡ä»¶: {conflict_path}")
        try:
            conflict_path.unlink()
            print("âœ… æˆåŠŸåˆ é™¤å†²çªæ–‡ä»¶ã€‚")
            return True
        except Exception as e:
            print(f"âŒ åˆ é™¤æ–‡ä»¶ {conflict_path} å¤±è´¥: {e}")
            return False
    elif conflict_path.is_dir():
         # Maybe it should be a symlink? Or maybe just needs removal.
         # Let's try removing it first, as it's the direct cause of 'mkdir' failure.
        print(f"å†²çªè·¯å¾„æ˜¯ä¸€ä¸ªç›®å½•ï¼Œå°è¯•åˆ é™¤ç›®å½•: {conflict_path}")
        try:
            shutil.rmtree(conflict_path)
            print("âœ… æˆåŠŸåˆ é™¤å†²çªç›®å½•ã€‚")
            return True
        except Exception as e:
            print(f"âŒ åˆ é™¤ç›®å½• {conflict_path} å¤±è´¥: {e}")
            return False
    else:
        print(f"â„¹ï¸ å†²çªè·¯å¾„ {conflict_path} å½“å‰ä¸å­˜åœ¨ï¼Œå¯èƒ½å·²è¢«å¤„ç†ã€‚")
        # Return True as the conflict state is resolved
        return True

def fix_symbolic_link_conflict(log_content):
    """ä¿®å¤ç¬¦å·é“¾æ¥å†²çª (ln: failed to create symbolic link ...: File exists)"""
    print("ğŸ”§ æ£€æµ‹åˆ°ç¬¦å·é“¾æ¥å†²çªï¼Œå°è¯•ä¿®å¤...")
    conflict_match = re.search(r'ln: failed to create symbolic link [\'"]?([^\'"]+)[\'"]?: File exists', log_content)
    if not conflict_match:
        print("â„¹ï¸ æœªåŒ¹é…åˆ° 'File exists' ç¬¦å·é“¾æ¥å†²çªæ—¥å¿—ã€‚")
        return False

    conflict_link_str = conflict_match.group(1).strip()
    conflict_link = Path(conflict_link_str)
    print(f"å†²çªç¬¦å·é“¾æ¥è·¯å¾„: {conflict_link}")

    # Safety check
    critical_dirs = [Path.cwd(), Path.home(), Path("/"), Path("~"), Path("."), Path("..")]
    if conflict_link.resolve() in [p.resolve() for p in critical_dirs] or not conflict_link_str:
        print(f"âŒ æ£€æµ‹åˆ°å…³é”®ç›®å½•æˆ–æ— æ•ˆè·¯å¾„ ({conflict_link_str})ï¼Œæ‹’ç»åˆ é™¤ï¼")
        return False

    if conflict_link.exists(): # Check if it exists (could be file, dir, or existing link)
        print(f"å°è¯•åˆ é™¤å·²å­˜åœ¨çš„æ–‡ä»¶/ç›®å½•/é“¾æ¥: {conflict_link}")
        try:
            if conflict_link.is_dir() and not conflict_link.is_symlink():
                 shutil.rmtree(conflict_link)
                 print(f"âœ… æˆåŠŸåˆ é™¤å†²çªç›®å½• {conflict_link}ã€‚")
            else:
                 conflict_link.unlink() # Works for files and symlinks
                 print(f"âœ… æˆåŠŸåˆ é™¤å†²çªæ–‡ä»¶/é“¾æ¥ {conflict_link}ã€‚")
            return True
        except Exception as e:
            print(f"âŒ åˆ é™¤ {conflict_link} å¤±è´¥: {e}")
            return False
    else:
        print(f"â„¹ï¸ å†²çªé“¾æ¥è·¯å¾„ {conflict_link} å½“å‰ä¸å­˜åœ¨ï¼Œå¯èƒ½å·²è¢«å¤„ç†ã€‚")
        return True # Conflict resolved


def fix_pkg_version_format():
    """ä¿®å¤ PKG_VERSION å’Œ PKG_RELEASE æ ¼å¼ (ç®€å•æ•°å­—æˆ–æ ‡å‡†æ ¼å¼)"""
    print("ğŸ”§ ä¿®å¤ Makefile ä¸­çš„ PKG_VERSION å’Œ PKG_RELEASE æ ¼å¼...")
    changed_count = 0
    makefile_pattern = "**/Makefile" # Look for Makefiles everywhere except build/staging/tmp
    ignore_dirs = ['build_dir', 'staging_dir', 'tmp', '.git']

    all_makefiles = list(Path('.').glob(makefile_pattern))
    print(f"æ‰¾åˆ° {len(all_makefiles)} ä¸ªæ½œåœ¨çš„ Makefile æ–‡ä»¶è¿›è¡Œæ£€æŸ¥...")

    processed_count = 0
    for makefile in all_makefiles:
        processed_count += 1
        if processed_count % 100 == 0:
             print(f"å·²æ£€æŸ¥ {processed_count}/{len(all_makefiles)}...")

        # Skip ignored directories
        if any(part in makefile.parts for part in ignore_dirs):
            continue

        try:
            with open(makefile, 'r', encoding='utf-8', errors='replace') as f:
                content = f.read()
            original_content = content
            current_content = content

            # Check if it's an OpenWrt package Makefile (basic check)
            if not ('include $(TOPDIR)/rules.mk' in content or 'include ../../buildinfo.mk' in content or 'include $(INCLUDE_DIR)/package.mk' in content):
                continue

            modified_in_file = False

            # --- Fix PKG_VERSION ---
            version_match = re.search(r'^(PKG_VERSION:=)(.*)$', current_content, re.MULTILINE)
            if version_match:
                current_version_line = version_match.group(0)
                current_version = version_match.group(2).strip()
                # Simple fix: remove leading 'v' if present
                if current_version.startswith('v'):
                    new_version = current_version.lstrip('v')
                    print(f"ğŸ”§ [{get_relative_path(str(makefile))}] ä¿®æ­£ PKG_VERSION: '{current_version}' -> '{new_version}'")
                    current_content = current_content.replace(current_version_line, f"PKG_VERSION:={new_version}", 1)
                    modified_in_file = True
                    current_version = new_version # Update for release check

                # More complex: Split version-release like 1.2-3 into VERSION=1.2, RELEASE=3
                # This is handled below by the RELEASE check

            # --- Fix PKG_RELEASE ---
            release_match = re.search(r'^(PKG_RELEASE:=)(.*)$', current_content, re.MULTILINE)
            version_present = 'PKG_VERSION:=' in current_content

            new_release_val = None
            if release_match:
                current_release_line = release_match.group(0)
                current_release = release_match.group(2).strip()
                # Must be a positive integer
                if not current_release.isdigit() or int(current_release) <= 0:
                    # Try to extract number if possible, e.g., from "beta1" -> "1"
                    num_part = re.search(r'(\d+)$', current_release)
                    if num_part:
                         new_release_val = num_part.group(1)
                         if int(new_release_val) <= 0: new_release_val = "1" # Ensure positive
                    else:
                         new_release_val = "1" # Default to 1

                    if new_release_val != current_release:
                         print(f"ğŸ”§ [{get_relative_path(str(makefile))}] ä¿®æ­£ PKG_RELEASE: '{current_release}' -> '{new_release_val}'")
                         current_content = current_content.replace(current_release_line, f"PKG_RELEASE:={new_release_val}", 1)
                         modified_in_file = True
            elif version_present:
                # PKG_RELEASE is missing, add it (default to 1)
                # Also handle case where version might be like "1.2.3-5"
                version_match_for_release = re.search(r'^(PKG_VERSION:=)(.*?)(-(\d+))?$', current_content, re.MULTILINE)
                if version_match_for_release:
                    current_version_line = version_match_for_release.group(0)
                    base_version = version_match_for_release.group(2).strip()
                    release_part = version_match_for_release.group(4)

                    if release_part and release_part.isdigit() and int(release_part) > 0:
                        # Version contains release, split it
                        new_version_line = f"PKG_VERSION:={base_version}"
                        new_release_line = f"PKG_RELEASE:={release_part}"
                        print(f"ğŸ”§ [{get_relative_path(str(makefile))}] åˆ†ç¦» PKG_VERSION/RELEASE: '{version_match_for_release.group(2)}{version_match_for_release.group(3)}' -> VERSION='{base_version}', RELEASE='{release_part}'")
                        # Replace version line and insert release line after it
                        current_content = current_content.replace(current_version_line, f"{new_version_line}\n{new_release_line}", 1)
                        modified_in_file = True
                    else:
                        # Version doesn't contain release, just add PKG_RELEASE:=1
                        new_release_line = "PKG_RELEASE:=1"
                        print(f"ğŸ”§ [{get_relative_path(str(makefile))}] æ·»åŠ ç¼ºå¤±çš„ PKG_RELEASE:=1")
                        # Insert after PKG_VERSION line
                        current_content = re.sub(r'^(PKG_VERSION:=.*)$', r'\1\n' + new_release_line, current_content, 1, re.MULTILINE)
                        modified_in_file = True
                else:
                     # Fallback if version format is weird, just add release line
                     new_release_line = "PKG_RELEASE:=1"
                     print(f"ğŸ”§ [{get_relative_path(str(makefile))}] æ·»åŠ ç¼ºå¤±çš„ PKG_RELEASE:=1 (Fallback)")
                     current_content = re.sub(r'^(PKG_VERSION:=.*)$', r'\1\n' + new_release_line, current_content, 1, re.MULTILINE)
                     modified_in_file = True

            # Write back if modified
            if modified_in_file:
                with open(makefile, 'w', encoding='utf-8') as f:
                    f.write(current_content)
                changed_count += 1

        except Exception as e:
            # Ignore errors reading/parsing files that might not be Makefiles
            if isinstance(e, UnicodeDecodeError):
                 pass # Skip binary files etc.
            else:
                 print(f"âš ï¸ å¤„ç†æ–‡ä»¶ {get_relative_path(str(makefile))} æ—¶è·³è¿‡ï¼ŒåŸå› : {e}")
            continue

    print(f"âœ… ä¿®å¤ PKG_VERSION/RELEASE å®Œæˆï¼Œå…±æ£€æŸ¥ {processed_count} ä¸ªæ–‡ä»¶ï¼Œä¿®æ”¹ {changed_count} ä¸ªæ–‡ä»¶ã€‚")
    # Return True if any file was changed, as this might require index update
    return changed_count > 0

def fix_metadata_errors():
    """ä¿®å¤ metadata é”™è¯¯ (åŒ…æ‹¬ç‰ˆæœ¬æ ¼å¼ï¼Œå¹¶æ›´æ–°ç´¢å¼•)"""
    print("ğŸ”§ å°è¯•ä¿®å¤ metadata ç›¸å…³é”™è¯¯...")
    metadata_changed = False

    # 1. Fix PKG_VERSION/RELEASE formats first
    if fix_pkg_version_format():
        metadata_changed = True

    # 2. If formats were fixed or potentially problematic, update feeds index
    if metadata_changed:
        print("â„¹ï¸ æ£€æµ‹åˆ° Makefile æ ¼å¼æ›´æ”¹ï¼Œæ›´æ–° feeds ç´¢å¼•...")
        try:
            update_cmd = ["./scripts/feeds", "update", "-i"]
            print(f"è¿è¡Œ: {' '.join(update_cmd)}")
            result = subprocess.run(update_cmd, check=False, capture_output=True, text=True, encoding='utf-8', errors='replace')
            if result.returncode != 0:
                print(f"âš ï¸ feeds update -i å¤±è´¥:\n{result.stderr[-500:]}")
            else:
                print("âœ… feeds update -i å®Œæˆã€‚")
            # Re-install might be needed if index changed significantly
            install_cmd = ["./scripts/feeds", "install", "-a"]
            print(f"è¿è¡Œ: {' '.join(install_cmd)}")
            result_install = subprocess.run(install_cmd, check=False, capture_output=True, text=True, encoding='utf-8', errors='replace')
            if result_install.returncode != 0:
                 print(f"âš ï¸ feeds install -a å¤±è´¥:\n{result_install.stderr[-500:]}")
            else:
                 print("âœ… feeds install -a å®Œæˆã€‚")

        except Exception as e:
            print(f"âŒ æ‰§è¡Œ feeds update/install æ—¶å‡ºé”™: {e}")
            metadata_changed = True # Assume change happened if error occurred

    # 3. Clean tmp directory as a general measure for metadata issues
    tmp_dir = Path("tmp")
    if tmp_dir.exists():
        print("ğŸ§¹ æ¸…ç† tmp ç›®å½•...")
        try:
            shutil.rmtree(tmp_dir)
            print("âœ… tmp ç›®å½•å·²æ¸…ç†ã€‚")
            metadata_changed = True # Cleaning tmp is a change
        except Exception as e:
            print(f"âš ï¸ æ¸…ç† tmp ç›®å½•å¤±è´¥: {e}")

    if metadata_changed:
        print("âœ… Metadata ä¿®å¤å°è¯•å®Œæˆã€‚")
    else:
        print("â„¹ï¸ æœªæ‰§è¡Œ Metadata ç›¸å…³ä¿®å¤ã€‚")

    return metadata_changed


def fix_depends_format(log_content):
    """è‡ªåŠ¨ä¿®å¤ Makefile ä¸­çš„æ— æ•ˆä¾èµ–é¡¹ (å¢å¼ºç‰ˆ v2)"""
    print("ğŸ”§ æ£€æµ‹åˆ°ä¾èµ–é¡¹æ ¼å¼é”™è¯¯ï¼Œå°è¯•è‡ªåŠ¨ä¿®å¤ Makefile ä¸­çš„ DEPENDS å­—æ®µ...")

    reported_files = set()
    warning_pattern = re.compile(r"WARNING: Makefile '([^']+)' has a dependency on '([^']*)', which does not exist")
    for match in warning_pattern.finditer(log_content):
        # è¿‡æ»¤æ‰ä¸€äº›å·²çŸ¥çš„ã€å¯èƒ½æ— å®³æˆ–éš¾ä»¥ä¿®å¤çš„è­¦å‘Š
        bad_dep = match.group(2)
        if bad_dep != 'PERL_TESTS' and 'gst1-mod-' not in bad_dep: # è¿‡æ»¤å·²çŸ¥å™ªéŸ³
            reported_files.add(match.group(1))

    fixed_count = 0
    processed_files = set()
    files_actually_fixed = []

    # ä¼˜å…ˆå¤„ç†æŠ¥å‘Šçš„æ–‡ä»¶
    if reported_files:
        print(f"ğŸ¯ ä¼˜å…ˆå¤„ç†æ—¥å¿—ä¸­æŠ¥å‘Šçš„ {len(reported_files)} ä¸ª Makefile...")
        for makefile_path_str in reported_files:
            makefile_path = Path(makefile_path_str)
            if makefile_path.exists() and makefile_path.is_file():
                if str(makefile_path.resolve()) not in processed_files:
                    if fix_single_makefile_depends(makefile_path):
                        fixed_count += 1
                        files_actually_fixed.append(makefile_path_str)
                    processed_files.add(str(makefile_path.resolve()))
            else:
                print(f"  âš ï¸ æŠ¥å‘Šçš„æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸æ˜¯æ–‡ä»¶: {makefile_path_str}")

    # --- (ç‰¹å®šé”™è¯¯åŒ…å¤„ç†é€»è¾‘ - å¯é€‰å¢å¼º) ---
    # å¦‚æœ apk_depends_invalid é”™è¯¯å‘ç”Ÿï¼Œä¹Ÿå°è¯•ä¿®å¤é‚£ä¸ªåŒ…çš„ Makefile
    apk_error_sig = get_error_signature(log_content)
    if "apk_depends_invalid" in apk_error_sig:
        failed_pkg_name = apk_error_sig.split(":")[-1]
        print(f"ğŸ¯ å°è¯•ä¿®å¤å¯¼è‡´ APK é”™è¯¯çš„åŒ… '{failed_pkg_name}' çš„ Makefile...")
        possible_makefile_paths = list(Path(".").glob(f"**/feeds/*/{failed_pkg_name}/Makefile")) + \
                                  list(Path(".").glob(f"package/*/{failed_pkg_name}/Makefile"))
        if possible_makefile_paths:
            makefile_path = possible_makefile_paths[0]
            if str(makefile_path.resolve()) not in processed_files:
                print(f"  â¡ï¸ å®šä½åˆ° Makefile: {makefile_path}")
                if fix_single_makefile_depends(makefile_path):
                    if makefile_path not in files_actually_fixed: # é¿å…é‡å¤è®¡æ•°
                         fixed_count += 1
                         files_actually_fixed.append(str(makefile_path))
                processed_files.add(str(makefile_path.resolve()))
            else:
                 print(f"  â„¹ï¸ åŒ… '{failed_pkg_name}' çš„ Makefile å·²å¤„ç†è¿‡ã€‚")
        else:
            print(f"  âš ï¸ æœªèƒ½æ‰¾åˆ°åŒ… '{failed_pkg_name}' çš„ Makefileã€‚")


    if fixed_count > 0:
        print(f"âœ… å…±ä¿®å¤ {fixed_count} ä¸ª Makefile ä¸­çš„ä¾èµ–æ ¼å¼é—®é¢˜: {files_actually_fixed}")
        print("  ğŸ”„ è¿è¡Œ './scripts/feeds update -i && ./scripts/feeds install -a' æ¥æ›´æ–°ä¾èµ–...")
        # ... (è¿è¡Œ feeds å‘½ä»¤çš„ä»£ç ä¿æŒä¸å˜) ...
        try:
            update_result = subprocess.run(["./scripts/feeds", "update", "-i"], check=False, capture_output=True, text=True, timeout=120)
            # ... (å¤„ç† update ç»“æœ) ...
            install_result = subprocess.run(["./scripts/feeds", "install", "-a"], check=False, capture_output=True, text=True, timeout=300)
            # ... (å¤„ç† install ç»“æœ) ...
        except Exception as e:
            print(f"  âš ï¸ æ›´æ–°/å®‰è£… feeds æ—¶å‡ºé”™: {e}")
        return True
    else:
        print("â„¹ï¸ æœªå‘ç°æˆ–æœªæˆåŠŸä¿®å¤éœ€è¦å¤„ç†çš„ DEPENDS å­—æ®µã€‚")
        return False



def fix_single_makefile_depends(makefile_path: Path):
    """ä¿®å¤å•ä¸ª Makefile ä¸­çš„ DEPENDS å­—æ®µ (å¢å¼ºç‰ˆ v2)"""
    try:
        with open(makefile_path, 'r', errors='replace') as f:
            content = f.read()
    except Exception as e:
        print(f"  âŒ è¯»å– Makefile å‡ºé”™ {makefile_path}: {e}")
        return False

    # æŸ¥æ‰¾ DEPENDS è¡Œ (æ”¯æŒ += å’Œå¤šè¡Œå®šä¹‰)
    # ä½¿ç”¨ re.DOTALL æ¥åŒ¹é…è·¨è¡Œçš„ DEPENDS
    depends_match = re.search(r'^(DEPENDS\s*[:+]?=\s*)((?:.*?\\\n)*.*)$', content, re.MULTILINE | re.IGNORECASE | re.DOTALL)
    if not depends_match:
        return False # æ²¡æœ‰ DEPENDS è¡Œ

    original_block = depends_match.group(0) # æ•´ä¸ªåŒ¹é…å—
    prefix = depends_match.group(1)
    depends_str_multiline = depends_match.group(2)

    # å°†å¤šè¡Œåˆå¹¶ä¸ºä¸€è¡Œï¼Œå¹¶ç§»é™¤è¡Œå°¾çš„åæ–œæ 
    depends_str = depends_str_multiline.replace('\\\n', ' ').replace('\n', ' ').strip()

    # æŒ‰ç©ºæ ¼åˆ†å‰²ä¾èµ–é¡¹
    depends_list = re.split(r'\s+', depends_str)
    cleaned_depends = []
    modified = False

    for dep in depends_list:
        dep = dep.strip()
        if not dep or dep == '\\': # è·³è¿‡ç©ºé¡¹å’Œæ®‹ç•™çš„åæ–œæ 
            continue

        original_dep = dep

        # ç§»é™¤å‰ç¼€ +@
        dep_prefix = ""
        if dep.startswith('+'):
            dep_prefix = "+"
            dep = dep[1:]
        elif dep.startswith('@'):
             dep_prefix = "@"
             dep = dep[1:]

        # ç§»é™¤ç‰ˆæœ¬çº¦æŸ
        dep_name = re.split(r'[<>=!~]', dep, 1)[0]

        # ç§»é™¤åƒåœ¾å­—ç¬¦å’Œæ¨¡å¼ (æ›´ä¸¥æ ¼)
        dep_name = re.sub(r'^(?:p|dependency|select|default|bool|tristate),+', '', dep_name, flags=re.IGNORECASE) # ç§»é™¤æ›´å¤šå‰ç¼€
        dep_name = dep_name.replace(',)', '').replace(')', '').replace('(', '').replace(',', '') # ç§»é™¤ ,) () ,
        dep_name = dep_name.strip('\'" ') # ç§»é™¤é¦–å°¾å¼•å·å’Œç©ºæ ¼

        # å†æ¬¡ç§»é™¤å¯èƒ½å¼•å…¥çš„ç‰ˆæœ¬çº¦æŸ
        dep_name = re.split(r'[<>=!~]', dep_name, 1)[0]

        # éªŒè¯æ¸…ç†åçš„åç§°
        if dep_name and re.match(r'^[a-zA-Z0-9._-]+$', dep_name) and dep_name != 'gst1-mod-':
            cleaned_dep_str = f"{dep_prefix}{dep_name}"
            cleaned_depends.append(cleaned_dep_str)
            if cleaned_dep_str != original_dep:
                modified = True
                print(f"  ğŸ”§ æ¸…ç†ä¾èµ–: '{original_dep}' -> '{cleaned_dep_str}' in {makefile_path}")
        elif dep_name:
             print(f"  âš ï¸ æ¸…ç†åçš„ä¾èµ– '{dep_name}' (æ¥è‡ª '{original_dep}') æ ¼å¼æ— æ•ˆï¼Œå·²ä¸¢å¼ƒã€‚æ–‡ä»¶: {makefile_path}")
             modified = True
        else:
             if original_dep:
                 print(f"  ğŸ—‘ï¸ ä¸¢å¼ƒæ— æ•ˆä¾èµ–: '{original_dep}' in {makefile_path}")
                 modified = True

    if modified:
        unique_depends = list(dict.fromkeys(cleaned_depends))
        new_depends_str = ' '.join(unique_depends)
        new_depends_line = f"{prefix}{new_depends_str}" # ä½¿ç”¨åŸå§‹å‰ç¼€

        # ä½¿ç”¨ strip() æ¯”è¾ƒï¼Œä½†æ›¿æ¢æ—¶è¦ç²¾ç¡®
        original_line_to_replace = original_block.strip()
        new_block_to_insert = new_depends_line # ä¿®å¤åé€šå¸¸ä¸éœ€è¦å¤šè¡Œ

        if new_block_to_insert.strip() != original_line_to_replace.strip():
            print(f"  âœ… ä¿®å¤ {makefile_path}:")
            print(f"    åŸå§‹å—: {original_line_to_replace}")
            print(f"    ä¿®å¤ä¸º: {new_block_to_insert.strip()}")
            try:
                # ç›´æ¥æ›¿æ¢æ•´ä¸ªåŒ¹é…å—
                new_content = content.replace(original_block, new_block_to_insert, 1)
                with open(makefile_path, 'w', encoding='utf-8') as f:
                    f.write(new_content)
                return True
            except Exception as e:
                 print(f"  âŒ å†™å› Makefile å¤±è´¥ {makefile_path}: {e}")
                 return False
        else:
             print(f"  â„¹ï¸ æ¸…ç†åå†…å®¹æœªå˜ (æˆ–ä»…ç©ºæ ¼å˜åŒ–): {makefile_path}")
             return False
    else:
        return False





def process_makefile_depends(makefile_path: Path):
    """Helper function to process DEPENDS in a single Makefile.
       Handles simple lists and complex Make constructs differently."""
    try:
        if makefile_path.is_symlink():
            pass # Process the symlink path

        if not makefile_path.is_file():
            return False

        with open(makefile_path, 'r', encoding='utf-8', errors='replace') as f:
            content = f.read()
        original_content = content

        is_package_makefile = ('define Package/' in content and 'endef' in content) or \
                              ('include $(TOPDIR)/rules.mk' in content or \
                               'include $(INCLUDE_DIR)/package.mk' in content or \
                               'include ../../buildinfo.mk' in content)
        if not is_package_makefile:
            return False

        depends_regex = r'^([ \t]*DEPENDS\+?=\s*)((?:.*?\\\n)*.*)$'
        modified_in_file = False
        new_content = content
        offset_adjustment = 0

        matches = list(re.finditer(depends_regex, content, re.MULTILINE))
        if not matches:
            return False

        for match in matches:
            start_index = match.start() + offset_adjustment
            end_index = match.end() + offset_adjustment

            original_depends_line_block = new_content[start_index:end_index]
            prefix = match.group(1)
            depends_value = match.group(2).replace('\\\n', ' ').strip()
            original_depends_value_for_log = depends_value # For potential logging

            # --- Check for complex Make syntax ($ or parenthesis) ---
            # We assume lines with these characters should not have duplicates removed after splitting
            is_complex = '$' in depends_value or '(' in depends_value

            # Split by whitespace - this is the source of potential issues with complex lines
            depends_list = re.split(r'\s+', depends_value)
            processed_depends = [] # Store parts after version cleaning
            needs_fix = False      # Track if any version constraint was removed

            for dep in depends_list:
                dep = dep.strip()
                if not dep:
                    continue

                dep_prefix = ""
                if dep.startswith('+') or dep.startswith('@'):
                    dep_prefix = dep[0]
                    dep_name = dep[1:]
                else:
                    dep_name = dep

                # Remove version constraints like >=, <=, =, >, <
                cleaned_name = re.split(r'[>=<]', dep_name, 1)[0].strip()

                if cleaned_name != dep_name:
                    needs_fix = True

                # Reconstruct the potentially cleaned part
                # We keep the original structure for complex lines, just potentially without version constraints
                current_part = f"{dep_prefix}{cleaned_name}" if cleaned_name else dep # Handle empty cleaned_name? Fallback to original dep.

                # Basic validation check (optional, but good practice)
                # If the part still looks weird after cleaning, maybe keep original?
                # For now, we trust the cleaning for version constraints.
                processed_depends.append(current_part)

            # --- Apply fixes only if version constraints were found ---
            if needs_fix:
                if is_complex:
                    # For complex lines (containing $ or parenthesis),
                    # simply join the processed parts back together.
                    # DO NOT remove duplicates, as it breaks Make syntax like $(foreach).
                    new_depends_str = ' '.join(processed_depends)
                    # Optional: Log that we handled a complex line differently
                    # print(f"  å¤„ç†å¤æ‚ä¾èµ–è¡Œ (ä»…ç§»é™¤ç‰ˆæœ¬çº¦æŸ): {get_relative_path(str(makefile_path))}")
                else:
                    # For simple lines, remove duplicates as before.
                    # print(f"  å¤„ç†ç®€å•ä¾èµ–è¡Œ (ç§»é™¤ç‰ˆæœ¬çº¦æŸå’Œé‡å¤é¡¹): {get_relative_path(str(makefile_path))}")
                    seen = {}
                    unique_depends = []
                    for item in processed_depends: # Iterate over the already cleaned parts
                        item_prefix = ""
                        item_name = item
                        if item.startswith('+') or item.startswith('@'):
                            item_prefix = item[0]
                            item_name = item[1:]

                        if not item_name: continue

                        if item_name not in seen:
                            seen[item_name] = item_prefix
                            unique_depends.append(item)
                        elif item_prefix == '@' and seen[item_name] == '+':
                            seen[item_name] = '@'
                            for i, old_item in enumerate(unique_depends):
                                if old_item == f"+{item_name}":
                                    unique_depends[i] = item
                                    break
                    new_depends_str = ' '.join(unique_depends)

                # Reconstruct the full line
                new_depends_line = f"{prefix}{new_depends_str}"

                # Replace the original block within the *current* state of new_content
                current_block_in_new_content = new_content[start_index:end_index]
                if current_block_in_new_content == original_depends_line_block: # Sanity check
                    new_content = new_content[:start_index] + new_depends_line + new_content[end_index:]
                    offset_adjustment += len(new_depends_line) - len(original_depends_line_block)
                    modified_in_file = True
                else:
                     print(f"âš ï¸ æ›¿æ¢ä¾èµ–å—æ—¶å‘ç”Ÿåç§»é”™è¯¯æˆ–å†…å®¹ä¸åŒ¹é… in {get_relative_path(str(makefile_path))}")
                     # Attempting replacement based on original value might be risky if content shifted significantly
                     # Let's try replacing based on the original block content found initially
                     # This is less safe but might work if only minor shifts occurred.
                     try:
                         # Find the original block again in the potentially modified new_content
                         current_start_index = new_content.find(original_depends_line_block, max(0, start_index - 50)) # Search around the original position
                         if current_start_index != -1:
                             current_end_index = current_start_index + len(original_depends_line_block)
                             print(f"  å°è¯•åŸºäºåŸå§‹å†…å®¹è¿›è¡Œæ›¿æ¢...")
                             new_content = new_content[:current_start_index] + new_depends_line + new_content[current_end_index:]
                             # Recalculate offset adjustment based on this replacement
                             offset_adjustment = len(new_content) - len(original_content) # Simpler recalculation
                             modified_in_file = True
                         else:
                              print(f"  æ— æ³•åœ¨å½“å‰å†…å®¹ä¸­é‡æ–°å®šä½åŸå§‹å—ï¼Œè·³è¿‡æ›¿æ¢ã€‚")
                              continue # Skip this match
                     except Exception as replace_err:
                          print(f"  åŸºäºåŸå§‹å†…å®¹æ›¿æ¢æ—¶å‡ºé”™: {replace_err}, è·³è¿‡æ›¿æ¢ã€‚")
                          continue # Skip this match if fallback replacement fails

        if modified_in_file:
            print(f"âœ… å·²ä¿®æ”¹ä¾èµ–é¡¹: {get_relative_path(str(makefile_path))}") # Log modified file
            # Write back the modified content only if changes were made
            with open(makefile_path, 'w', encoding='utf-8') as f:
                f.write(new_content)
            return True # Indicate modification

    except Exception as e:
        if isinstance(e, UnicodeDecodeError):
             pass # Skip files that cannot be decoded
        elif isinstance(e, FileNotFoundError):
             print(f"âš ï¸ å¤„ç†æ–‡ä»¶æ—¶æœªæ‰¾åˆ°: {get_relative_path(str(makefile_path))}")
        else:
             # Log other errors during file processing
             print(f"âš ï¸ å¤„ç†æ–‡ä»¶ {get_relative_path(str(makefile_path))} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return False

    return False # No modification needed or happened
def fix_lua_neturl_download(log_content):
    """ä¿®å¤ lua-neturl ä¸‹è½½é—®é¢˜ (éœ€è¦ requests å’Œ beautifulsoup4)"""
    if not (requests and BeautifulSoup):
        print("âŒ è·³è¿‡ lua-neturl ä¸‹è½½ä¿®å¤ï¼šç¼ºå°‘ 'requests' æˆ– 'beautifulsoup4' åº“ã€‚")
        return False

    print("ğŸ”§ æ£€æµ‹åˆ° lua-neturl ä¸‹è½½é”™è¯¯ï¼Œå°è¯•æ›´æ–° Makefile...")

    makefile_path = None
    for pattern in ["feeds/small8/lua-neturl/Makefile", "package/feeds/small8/lua-neturl/Makefile"]:
        path = Path(pattern)
        if path.exists():
            makefile_path = path
            break

    if not makefile_path:
        print("âŒ æ— æ³•æ‰¾åˆ° lua-neturl çš„ Makefileã€‚")
        return False

    print(f"æ‰¾åˆ° Makefile: {makefile_path}")

    try:
        # 1. Get latest tag from GitHub
        print("ğŸŒ æ­£åœ¨ä» GitHub è·å–æœ€æ–°çš„ neturl tag...")
        response = requests.get("https://github.com/golgote/neturl/tags", timeout=15)
        response.raise_for_status() # Raise exception for bad status codes
        soup = BeautifulSoup(response.text, 'html.parser')
        # Find tags like vX.Y.Z or vX.Y.Z-N
        tag_elements = soup.find_all('a', href=re.compile(r'/golgote/neturl/releases/tag/v[\d.-]+'))
        tags = [tag.text.strip() for tag in tag_elements if re.match(r'^v[\d.-]+$', tag.text.strip())]

        if not tags:
            print("âš ï¸ æœªèƒ½åœ¨ GitHub é¡µé¢æ‰¾åˆ°æœ‰æ•ˆçš„ç‰ˆæœ¬æ ‡ç­¾ï¼Œä½¿ç”¨é»˜è®¤å€¼ v1.2-1ã€‚")
            latest_tag = "v1.2-1"
        else:
            # Simple sort might work for versions like v1.2, v1.10 but fail for v1.2-1 vs v1.2
            # Let's just take the first one found, assuming GitHub lists newest first
            latest_tag = tags[0]
            print(f"âœ… è·å–åˆ°æœ€æ–°/ç¬¬ä¸€ä¸ª tag: {latest_tag}")

        # 2. Derive version, source filename, URL, and expected build dir
        raw_version_part = latest_tag.lstrip('v') # e.g., 1.2-1
        pkg_version = re.match(r'^(\d+(\.\d+)*)', raw_version_part).group(1) # e.g., 1.2
        pkg_release = "1" # Default release
        release_match = re.search(r'-(\d+)$', raw_version_part)
        if release_match:
            pkg_release = release_match.group(1)
            pkg_source_filename = f"neturl-{raw_version_part}.tar.gz"
        pkg_source_url = f"https://github.com/golgote/neturl/archive/refs/tags/{latest_tag}.tar.gz"
        expected_build_subdir = f"neturl-{raw_version_part}" # Directory inside tarball

        # 3. Download the source tarball to calculate hash
        dl_dir = Path("./dl")
        dl_dir.mkdir(exist_ok=True)
        tarball_path = dl_dir / pkg_source_filename

        print(f"Downloading {pkg_source_url} to {tarball_path}...")
        try:
            # Use wget or curl, whichever is available
            if shutil.which("wget"):
                download_cmd = ["wget", "-q", "-O", str(tarball_path), pkg_source_url]
            elif shutil.which("curl"):
                download_cmd = ["curl", "-s", "-L", "-o", str(tarball_path), pkg_source_url]
            else:
                print("âŒ wget å’Œ curl éƒ½ä¸å¯ç”¨ï¼Œæ— æ³•ä¸‹è½½ã€‚")
                return False
            subprocess.run(download_cmd, check=True, timeout=60)
            print("âœ… ä¸‹è½½æˆåŠŸã€‚")
        except (subprocess.CalledProcessError, subprocess.TimeoutExpired) as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            if tarball_path.exists(): tarball_path.unlink() # Clean up partial download
            return False

        # 4. Calculate SHA256 hash
        sha256_hash = hashlib.sha256()
        with open(tarball_path, "rb") as f:
            while True:
                byte_block = f.read(4096)
                if not byte_block:
                    break
                sha256_hash.update(byte_block)
        sha256_hex = sha256_hash.hexdigest()
        print(f"âœ… è®¡ç®—å¾—åˆ° SHA256 å“ˆå¸Œå€¼: {sha256_hex}")

        # 5. Update the Makefile
        with open(makefile_path, 'r', encoding='utf-8', errors='replace') as f:
            content = f.read()
        original_content = content

        content = re.sub(r'^(PKG_VERSION:=).*', rf'\g<1>{pkg_version}', content, flags=re.MULTILINE)
        content = re.sub(r'^(PKG_RELEASE:=).*', rf'\g<1>{pkg_release}', content, flags=re.MULTILINE)
        content = re.sub(r'^(PKG_SOURCE:=).*', rf'\g<1>{pkg_source_filename}', content, flags=re.MULTILINE)
        content = re.sub(r'^(PKG_SOURCE_URL:=).*', rf'\g<1>{pkg_source_url}', content, flags=re.MULTILINE)
        content = re.sub(r'^(PKG_HASH:=).*', rf'\g<1>{sha256_hex}', content, flags=re.MULTILINE)

        # Ensure PKG_BUILD_DIR is correct
        build_dir_line = f"PKG_BUILD_DIR:=$(BUILD_DIR)/{expected_build_subdir}"
        build_dir_regex = r'^\s*PKG_BUILD_DIR:=\$\(BUILD_DIR\)/.*'
        if not re.search(build_dir_regex, content, re.MULTILINE):
             insert_after = r'^\s*PKG_HASH:=[^\n]+'
             content = re.sub(f'({insert_after})', f'\\1\n{build_dir_line}', content, 1, re.MULTILINE)
        elif not re.search(r'^\s*PKG_BUILD_DIR:=\$\(BUILD_DIR\)/' + re.escape(expected_build_subdir) + r'\s*$', content, re.MULTILINE):
             content = re.sub(build_dir_regex, build_dir_line, content, 1, re.MULTILINE)

        if content != original_content:
            with open(makefile_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"âœ… Makefile {makefile_path} å·²æ›´æ–°ã€‚")

            # Clean the package to apply changes
            pkg_rel_path = makefile_path.parent.relative_to(Path.cwd())
            print(f"ğŸ§¹ æ¸…ç†æ—§çš„æ„å»ºæ–‡ä»¶: {pkg_rel_path}")
            subprocess.run(["make", f"{pkg_rel_path}/clean", "V=s"], check=False, capture_output=True)
            # Optional: Update feeds index again after fixing a specific package
            # print("Updating feeds index...")
            # subprocess.run(["./scripts/feeds", "update", "-i"], check=False, capture_output=True)
            # subprocess.run(["./scripts/feeds", "install", "lua-neturl"], check=False, capture_output=True)

            print("â³ ç­‰å¾… 2 ç§’åé‡è¯•...")
            time.sleep(2)
            return True
        else:
            print("â„¹ï¸ Makefile æ— éœ€æ›´æ–°ã€‚ä¸‹è½½é—®é¢˜å¯èƒ½ç”±ç½‘ç»œæˆ–å…¶ä»–åŸå› å¼•èµ·ã€‚")
            # Even if Makefile is correct, the download might have failed before.
            # Returning True allows a retry with the potentially fixed download.
            return True

    except requests.exceptions.RequestException as e:
         print(f"âŒ ç½‘ç»œé”™è¯¯: æ— æ³•ä» GitHub è·å–ä¿¡æ¯: {e}")
         return False
    except Exception as e:
        print(f"âŒ æ›´æ–° lua-neturl Makefile æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
        return False

def fix_apk_directly():
    """ç›´æ¥ä¿®å¤ luci.mk ä¸­çš„ apk mkpkg è°ƒç”¨ä»¥æ¸…ç†ä¾èµ– (v3)"""
    print("ğŸ”§ å°è¯•ç›´æ¥ä¿®æ”¹ luci.mk ä¸­çš„ apk mkpkg è°ƒç”¨ä»¥æ¸…ç†ä¾èµ–...")
    luci_mk_path = None
    possible_paths = ["feeds/luci/luci.mk", "package/feeds/luci/luci.mk", "package/luci/luci.mk"]
    for path in possible_paths:
        if os.path.exists(path):
            luci_mk_path = path
            break

    if not luci_mk_path:
        print(f"âš ï¸ æ‰¾ä¸åˆ° luci.mk (æ£€æŸ¥è·¯å¾„: {possible_paths})")
        return False

    try:
        with open(luci_mk_path, 'r', encoding='utf-8') as f:
            original_content = f.read()

        content = original_content
        made_change = False

        # æŸ¥æ‰¾è°ƒç”¨ apk mkpkg å¹¶åŒ…å« --info "depends:$(PKG_DEPENDS)" çš„è¡Œ
        # è¿™ä¸ªæ¨¡å¼éœ€è¦ç²¾ç¡®åŒ¹é…ï¼Œå¯èƒ½éœ€è¦æ ¹æ®å®é™… luci.mk å†…å®¹è°ƒæ•´
        # å‡è®¾ apk mkpkg å‘½ä»¤åœ¨ä¸€è¡Œå†…
        apk_mkpkg_pattern = re.compile(r'(\$\(STAGING_DIR_HOST\)/bin/apk mkpkg .*?--info "depends:)(\$\(PKG_DEPENDS\))(".*)', re.IGNORECASE)

        # æ›¿æ¢æ–¹æ¡ˆï¼šåœ¨è°ƒç”¨ apk mkpkg å‰ï¼Œç”¨ shell å‘½ä»¤æ¸…ç† PKG_DEPENDS
        # æ³¨æ„ï¼šè¿™é‡Œçš„ shell å‘½ä»¤éœ€è¦ä»”ç»†æ„é€ ï¼Œé¿å…å¼•å·å’Œç‰¹æ®Šå­—ç¬¦é—®é¢˜
        # ä½¿ç”¨ä¸€ä¸ªä¸´æ—¶å˜é‡ CLEANED_DEPENDS
        replacement_logic = r"""\
        CLEANED_DEPENDS=$$$$(echo '$(PKG_DEPENDS)' | tr ' ' '\\n' | sed -e 's/[<>=!~].*//g' -e '/^$$/d' | sort -u | tr '\\n' ' ' | sed -e 's/ $$//g'); \
        \1$$$$(CLEANED_DEPENDS)\3
"""
        # ä½¿ç”¨ re.sub è¿›è¡Œæ›¿æ¢
        modified_content, num_replacements = apk_mkpkg_pattern.subn(replacement_logic, content)

        if num_replacements > 0:
            print(f"  âœ… åœ¨ {luci_mk_path} ä¸­æ‰¾åˆ°å¹¶ä¿®æ”¹äº† {num_replacements} å¤„ apk mkpkg è°ƒç”¨ä»¥æ¸…ç†ä¾èµ–ã€‚")
            content = modified_content
            made_change = True
            # ç§»é™¤å¯èƒ½å­˜åœ¨çš„æ—§çš„ CleanDependString å‡½æ•°å®šä¹‰ï¼Œå› ä¸ºå®ƒä¸å†éœ€è¦
            content = re.sub(r'^# APK dependency fix.*?endef\s*$', '', content, flags=re.MULTILINE | re.DOTALL).strip()

        else:
            print(f"  âš ï¸ æœªèƒ½åœ¨ {luci_mk_path} ä¸­æ‰¾åˆ°é¢„æœŸçš„ apk mkpkg è°ƒç”¨æ¨¡å¼è¿›è¡Œä¿®æ”¹ã€‚")
            # æ£€æŸ¥æ˜¯å¦å·²ç»åº”ç”¨è¿‡ç±»ä¼¼çš„ä¿®å¤ (æŸ¥æ‰¾ CLEANED_DEPENDS)
            if "CLEANED_DEPENDS=" in content and "--info \"depends:$$$$(CLEANED_DEPENDS)\"" in content:
                 print("  â„¹ï¸ ä¼¼ä¹å·²åº”ç”¨è¿‡ç±»ä¼¼çš„ä¿®å¤é€»è¾‘ã€‚")
                 made_change = False # æ ‡è®°ä¸ºæœªåšä¿®æ”¹ï¼Œä½†è®¤ä¸ºå°è¯•è¿‡
            else:
                 # å¦‚æœæ‰¾ä¸åˆ°æ¨¡å¼ï¼Œå¹¶ä¸”æ²¡æœ‰ä¿®å¤ç—•è¿¹ï¼Œåˆ™æ­¤æ–¹æ³•å¤±è´¥
                 print(f"  âŒ æ— æ³•åº”ç”¨ä¿®å¤é€»è¾‘åˆ° {luci_mk_path}ã€‚")
                 return False


        # å¦‚æœåšäº†ä¿®æ”¹ï¼Œå†™å›æ–‡ä»¶å¹¶æ¸…ç†
        if made_change and content.strip() != original_content.strip():
            print(f"  ğŸ’¾ å†™å›ä¿®æ”¹åˆ° {luci_mk_path}...")
            with open(luci_mk_path, 'w', encoding='utf-8') as f:
                f.write(content + "\n") # ç¡®ä¿æœ«å°¾æœ‰æ¢è¡Œ

            # æ¸…ç† tmp ç›®å½•
            print("  ğŸ§¹ æ¸…ç† tmp ç›®å½•...")
            if os.path.exists("tmp"):
                try:
                    shutil.rmtree("tmp")
                    print("    âœ… tmp ç›®å½•å·²åˆ é™¤ã€‚")
                except Exception as e:
                    print(f"    âš ï¸ æ¸…ç† tmp ç›®å½•å¤±è´¥: {e}")
            else:
                print("    â„¹ï¸ tmp ç›®å½•ä¸å­˜åœ¨ã€‚")

            # æ¸…ç†ç›¸å…³åŒ… (DIRCLEAN)
            print("  ğŸ§¹ æ¸…ç†ç›¸å…³æ„å»ºç¼“å­˜ (DIRCLEAN)...")
            # ... (æ¸…ç†åŒ…çš„é€»è¾‘ï¼ŒåŒä¸Š) ...
            packages_to_clean = [...] # å®šä¹‰éœ€è¦æ¸…ç†çš„åŒ…
            for pkg_path in set(packages_to_clean):
                 # ... (æ‰§è¡Œ make DIRCLEAN=1 .../clean) ...
                 pass

            return True
        elif made_change: # å†…å®¹ç›¸åŒï¼Œè¯´æ˜ä¹‹å‰çš„ä¿®æ”¹å°±æ˜¯è¿™ä¸ª
             print(f"  â„¹ï¸ {luci_mk_path} å†…å®¹å·²åŒ…å«ä¿®å¤é€»è¾‘ï¼Œæ— éœ€å†™å›ã€‚")
             return True # è®¤ä¸ºå°è¯•è¿‡
        else: # made_change ä¸º False
            print(f"  â„¹ï¸ {luci_mk_path} æ— éœ€ä¿®æ”¹ã€‚")
            return True # è®¤ä¸ºå°è¯•è¿‡

    except Exception as e:
        print(f"âŒ ç›´æ¥ä¿®å¤ luci.mk ä¸­çš„ apk mkpkg è°ƒç”¨æ—¶å‡ºé”™: {e}")
        return False

def fix_toolchain_provides_syntax(log_content):
    """ä¿®å¤ toolchain Makefile ä¸­ provides å­—æ®µæœ«å°¾çš„ç©ºæ ¼å¯¼è‡´çš„è¯­æ³•é”™è¯¯"""
    print("ğŸ”§ æ£€æµ‹åˆ° toolchain provides è¯­æ³•é”™è¯¯ï¼Œå°è¯•ä¿®å¤...")
    makefile_path = Path("package/libs/toolchain/Makefile")
    if not makefile_path.exists():
        print("âŒ æ‰¾ä¸åˆ° package/libs/toolchain/Makefileã€‚")
        return False

    fixed = False
    try:
        with open(makefile_path, 'r', encoding='utf-8', errors='replace') as f:
            content = f.read()
        original_content = content

        # Find lines like: --info "provides: name=version " (with trailing space)
        # And remove the trailing space inside the quotes
        # Use a function for replacement to handle multiple occurrences
        def remove_trailing_space(match):
            nonlocal fixed
            provides_val = match.group(1)
            if provides_val.endswith(" "):
                fixed = True
                return f'--info "provides:{provides_val.rstrip()} "' # Keep space after quotes if any
            return match.group(0) # No change

        content = re.sub(r'--info "provides:([^"]+?)\s*"', remove_trailing_space, content)

        if fixed:
            with open(makefile_path, 'w', encoding='utf-8') as f:
                f.write(content)
            print(f"âœ… å·²ä¿®å¤ {makefile_path} ä¸­çš„ provides å­—æ®µç©ºæ ¼é—®é¢˜ã€‚")
            # Clean toolchain package
            print("ğŸ§¹ æ¸…ç† toolchain æ„å»º...")
            subprocess.run(["make", "package/libs/toolchain/clean", "V=s"], check=False, capture_output=True)
            return True
        else:
            print("â„¹ï¸ æœªåœ¨ toolchain Makefile ä¸­æ‰¾åˆ°éœ€è¦ä¿®å¤çš„ provides å­—æ®µç©ºæ ¼ã€‚")
            return False

    except Exception as e:
        print(f"âŒ ä¿®å¤ toolchain provides è¯­æ³•æ—¶å‡ºé”™: {e}")
        return False

def fix_apk_wrapper_issues(log_content):
    """å¤„ç†ä¸ apk wrapper ç›¸å…³çš„é—®é¢˜ (ç§»é™¤æˆ–ä¿®å¤)"""
    wrapper_path = Path("staging_dir/host/bin/apk")
    real_path = Path("staging_dir/host/bin/apk.real")

    if real_path.exists(): # Wrapper exists (or did exist)
        print("ğŸ”§ æ£€æµ‹åˆ° apk wrapper æˆ–å…¶æ®‹ç•™ï¼Œè¿›è¡Œå¤„ç†...")
        if wrapper_path.exists():
             # Check if it's our wrapper causing syntax errors
             syntax_error_in_log = "Syntax error:" in log_content and str(wrapper_path) in log_content
             if syntax_error_in_log:
                  print("âš ï¸ æ£€æµ‹åˆ° wrapper è„šæœ¬å­˜åœ¨è¯­æ³•é”™è¯¯ï¼Œç§»é™¤ wrapper å¹¶æ¢å¤åŸå§‹ apk...")
                  try:
                       wrapper_path.unlink()
                       real_path.rename(wrapper_path)
                       print("âœ… å·²æ¢å¤åŸå§‹ apk å‘½ä»¤ã€‚")
                       return True # Action taken
                  except Exception as e:
                       print(f"âŒ æ¢å¤åŸå§‹ apk æ—¶å‡ºé”™: {e}")
                       return False
             else:
                  print("â„¹ï¸ wrapper å­˜åœ¨ä½†æ—¥å¿—ä¸­æœªæ£€æµ‹åˆ°å…¶è¯­æ³•é”™è¯¯ã€‚")
                  # Maybe the wrapper fixed the depends issue but another error occurred?
                  # Or maybe the wrapper itself is fine but didn't fix the root cause.
                  # Let's leave it for now, unless specific wrapper errors occur.
                  return False # No action taken on the wrapper itself
        else:
             # Wrapper script is missing, but real binary exists. Restore.
             print("âš ï¸ wrapper è„šæœ¬ä¸¢å¤±ï¼Œä½†å¤‡ä»½å­˜åœ¨ã€‚æ¢å¤åŸå§‹ apk...")
             try:
                  real_path.rename(wrapper_path)
                  print("âœ… å·²æ¢å¤åŸå§‹ apk å‘½ä»¤ã€‚")
                  return True # Action taken
             except Exception as e:
                  print(f"âŒ æ¢å¤åŸå§‹ apk æ—¶å‡ºé”™: {e}")
                  return False
    else:
         # No wrapper seems to be active
         return False # No action taken

def fix_apk_depends_logic():
    """
    ç»¼åˆå¤„ç† APK ä¾èµ–æ ¼å¼é”™è¯¯ (Error 99 æˆ– invalid value)ã€‚
    ä¼˜å…ˆå°è¯•ä¿®æ”¹ luci.mkã€‚
    """
    print("ğŸ”§ å°è¯•ä¿®å¤ APK ä¾èµ–æ ¼å¼é€»è¾‘ (ä¼˜å…ˆä¿®æ”¹ luci.mk)...")
    luci_mk_path = None
    # Prefer feed path if it exists
    feed_path = Path("feeds/luci/luci.mk")
    package_path = Path("package/feeds/luci/luci.mk") # Fallback if using older structure/local copy

    if feed_path.exists():
        luci_mk_path = feed_path
    elif package_path.exists():
        luci_mk_path = package_path

    if luci_mk_path:
        if fix_apk_directly(luci_mk_path):
            return True # Fixed by modifying luci.mk
        else:
            # If modifying luci.mk didn't work or wasn't needed,
            # maybe the issue is in *another* package's depends definition.
            # Try the global DEPENDS format fix as a fallback.
            print("â„¹ï¸ ä¿®æ”¹ luci.mk æœªè§£å†³é—®é¢˜æˆ–æ— éœ€ä¿®æ”¹ï¼Œå°è¯•å…¨å±€ DEPENDS æ ¼å¼ä¿®å¤...")
            # We need log content for the global fix, assume it's available in the caller
            # This function now just signals if the primary fix worked.
            return False # Indicate primary fix didn't solve it
    else:
        print("âŒ æ‰¾ä¸åˆ° feeds/luci/luci.mk æˆ– package/feeds/luci/luci.mkã€‚")
        return False

def fix_apk_directly():
    """ç›´æ¥ä¿®å¤ APK ä¾èµ–å‘½ä»¤è¡Œå‚æ•° (ä¿®æ”¹ luci.mk)"""
    print("ğŸ”§ å°è¯•ç›´æ¥ä¿®æ”¹ luci.mk æ¥ä¿®å¤ APK ä¾èµ–æ ¼å¼...")
    luci_mk_path = None
    # ä¼˜å…ˆä½¿ç”¨ feeds ä¸­çš„è·¯å¾„
    possible_paths = ["feeds/luci/luci.mk", "package/feeds/luci/luci.mk", "package/luci/luci.mk"]
    for path in possible_paths:
        if os.path.exists(path):
            luci_mk_path = path
            break

    if not luci_mk_path:
        print(f"âš ï¸ æ‰¾ä¸åˆ° luci.mk (æ£€æŸ¥è·¯å¾„: {possible_paths})")
        return False

    try:
        with open(luci_mk_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # æ£€æŸ¥æ˜¯å¦å·²ç»ä¿®å¤è¿‡
        if "# APK dependency fix" in content:
            print(f"â„¹ï¸ {luci_mk_path} ä¼¼ä¹å·²ç»åº”ç”¨è¿‡ä¿®å¤ã€‚")
            # å³ä½¿å·²ä¿®å¤ï¼Œä¹Ÿè¿”å› Trueï¼Œè¡¨ç¤ºå°è¯•è¿‡æ­¤æ–¹æ³•
            return True

        # æ·»åŠ ä¿®å¤ä»£ç ï¼Œä½¿ç”¨ sed æ¥æ¸…ç†ä¾èµ–é¡¹
        fix_code = """
# APK dependency fix
define CleanDependString
$(shell echo $(1) | tr ' ' '\\n' | sed -e 's/[<>=!~].*//g' -e '/^$$/d' | sort -u | tr '\\n' ' ' | sed -e 's/ $$//g')
endef

"""
        # æŸ¥æ‰¾æ’å…¥ç‚¹ï¼Œé€šå¸¸åœ¨æ–‡ä»¶é¡¶éƒ¨æˆ– include ä¹‹å
        insert_pos = content.find("include $(TOPDIR)/rules.mk")
        if insert_pos != -1:
            insert_pos = content.find('\n', insert_pos) + 1
            new_content = content[:insert_pos] + fix_code + content[insert_pos:]
        else:
            new_content = fix_code + content # æ”¾åœ¨æ–‡ä»¶å¼€å¤´

        # ä¿®æ”¹ä¾èµ–å‚æ•°å¤„ç†
        # åŒ¹é… --info "depends:..." éƒ¨åˆ†ï¼Œç¡®ä¿æ›¿æ¢æ­£ç¡®
        # ä½¿ç”¨ re.sub æ›´å®‰å…¨åœ°å¤„ç†å¯èƒ½çš„å¤šè¡Œæˆ–å¤æ‚æƒ…å†µ
        original_depends_pattern = r'(--info "depends:)(\$\(PKG_DEPENDS\))(")'
        replacement_pattern = r'\1$(call CleanDependString,\2)\3'

        modified_content, num_replacements = re.subn(original_depends_pattern, replacement_pattern, new_content)

        if num_replacements > 0:
            with open(luci_mk_path, 'w', encoding='utf-8') as f:
                f.write(modified_content)
            print(f"âœ… å·²åœ¨ {luci_mk_path} ä¸­æ·»åŠ ä¾èµ–é¡¹æ¸…ç†å‡½æ•°å¹¶ä¿®æ”¹äº† {num_replacements} å¤„ä¾èµ–å‚æ•°ã€‚")

            # æ¸…ç†å¯èƒ½å—å½±å“çš„åŒ…çš„æ„å»ºç¼“å­˜ (ç¤ºä¾‹ï¼Œå¯èƒ½éœ€è¦æ›´ç²¾ç¡®)
            print("ğŸ§¹ æ¸…ç† luci ç›¸å…³æ„å»ºç¼“å­˜...")
            subprocess.run(["make", "package/feeds/luci/luci-base/clean"], check=False, capture_output=True)
            subprocess.run(["make", "package/feeds/small8/luci-lib-taskd/clean"], check=False, capture_output=True)
            # æ¸…ç† toolchain ç¼“å­˜ï¼Œå› ä¸ºå®ƒä¹Ÿè°ƒç”¨ apk
            subprocess.run(["make", "package/libs/toolchain/clean"], check=False, capture_output=True)
            return True
        else:
            print(f"âš ï¸ æœªèƒ½åœ¨ {luci_mk_path} ä¸­æ‰¾åˆ° '--info \"depends:$(PKG_DEPENDS)\"' è¿›è¡Œæ›¿æ¢ã€‚")
            # å³ä½¿æœªæ›¿æ¢ï¼Œä½†æ–‡ä»¶å­˜åœ¨ä¸”å°è¯•è¿‡ï¼Œä¹Ÿç®—æ˜¯ä¸€ç§å°è¯•
            return True # è¿”å› True è¡¨ç¤ºå°è¯•è¿‡ï¼Œä½†ä¸ä¸€å®šæˆåŠŸä¿®æ”¹

    except Exception as e:
        print(f"âŒ ç›´æ¥ä¿®å¤ APK ä¾èµ– (luci.mk) æ—¶å‡ºé”™: {e}")
        return False

def fix_luci_lib_taskd_makefile():
    """ä¿®å¤ luci-lib-taskd çš„ä¾èµ–æ ¼å¼é—®é¢˜ (åˆ›å»º APK wrapper - ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ)"""
    print("ğŸ› ï¸ ä½¿ç”¨æ‹¦æˆªæ–¹æ³•ä¿®å¤ APK ä¾èµ–æ ¼å¼é—®é¢˜ (å¤‡é€‰æ–¹æ¡ˆ)...")

    apk_script_path = "staging_dir/host/bin/apk"
    apk_real_path = "staging_dir/host/bin/apk.real"

    # ç¡®ä¿ staging_dir/host/bin å­˜åœ¨
    host_bin_dir = Path("staging_dir/host/bin")
    if not host_bin_dir.exists():
        print(f"âš ï¸ ç›®å½• {host_bin_dir} ä¸å­˜åœ¨ï¼Œæ— æ³•åˆ›å»º wrapperã€‚")
        return False
    host_bin_dir.mkdir(parents=True, exist_ok=True) # å°è¯•åˆ›å»º

    # å¦‚æœ wrapper å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤ï¼Œå°è¯•æ¢å¤åŸå§‹æ–‡ä»¶
    if os.path.exists(apk_script_path) and os.path.realpath(apk_script_path) != apk_script_path: # æ£€æŸ¥æ˜¯å¦æ˜¯ç¬¦å·é“¾æ¥æˆ–æˆ‘ä»¬çš„è„šæœ¬
         if os.path.exists(apk_real_path):
             print(f"â„¹ï¸ æ£€æµ‹åˆ°ç°æœ‰ wrapperï¼Œå°è¯•æ¢å¤åŸå§‹ apk...")
             try:
                 os.remove(apk_script_path)
                 os.rename(apk_real_path, apk_script_path)
                 os.chmod(apk_script_path, 0o755) # æ¢å¤æƒé™
             except Exception as e:
                 print(f"âš ï¸ æ¢å¤åŸå§‹ apk å¤±è´¥: {e}")
                 # ç»§ç»­å°è¯•åˆ›å»ºæ–°çš„ wrapper
         else:
              print(f"âš ï¸ æ£€æµ‹åˆ°ç°æœ‰ wrapper ä½†æ— å¤‡ä»½ ({apk_real_path})ï¼Œå°è¯•ç›´æ¥è¦†ç›–...")
              try:
                  os.remove(apk_script_path)
              except Exception as e:
                  print(f"âš ï¸ åˆ é™¤ç°æœ‰ wrapper å¤±è´¥: {e}")


    # æ£€æŸ¥åŸå§‹ apk æ˜¯å¦å­˜åœ¨
    if not os.path.exists(apk_script_path) or os.path.islink(apk_script_path):
         print(f"âš ï¸ æ‰¾ä¸åˆ°åŸå§‹ apk å‘½ä»¤ ({apk_script_path}) æˆ–å®ƒæ˜¯ä¸€ä¸ªé“¾æ¥ã€‚")
         # å°è¯•å¯»æ‰¾å¯èƒ½çš„çœŸå®è·¯å¾„
         real_apk_found = False
         for potential_real_path in host_bin_dir.glob("apk*"):
             if potential_real_path.name != "apk" and not potential_real_path.name.endswith(".real"):
                 try:
                     # å‡è®¾æ‰¾åˆ°çš„æ˜¯åŸå§‹ apkï¼Œé‡å‘½åå®ƒ
                     os.rename(potential_real_path, apk_script_path)
                     os.chmod(apk_script_path, 0o755)
                     print(f"âœ… æ‰¾åˆ°äº†å¯èƒ½çš„åŸå§‹ apk å¹¶é‡å‘½åä¸º: {apk_script_path}")
                     real_apk_found = True
                     break
                 except Exception as e:
                     print(f"âš ï¸ å°è¯•é‡å‘½å {potential_real_path} å¤±è´¥: {e}")
         if not real_apk_found:
              print(f"âŒ æ— æ³•å®šä½åŸå§‹ apk å‘½ä»¤ï¼Œæ— æ³•åˆ›å»º wrapperã€‚")
              return False


    # åˆ›å»º wrapper
    try:
        print(f"â„¹ï¸ å¤‡ä»½åŸå§‹ apk åˆ° {apk_real_path}")
        shutil.move(apk_script_path, apk_real_path) # ä½¿ç”¨ shutil.move æ›´å¯é 
        os.chmod(apk_real_path, 0o755)

        # åˆ›å»ºè„šæœ¬æ›¿æ¢åŸå‘½ä»¤ - ä½¿ç”¨æ›´å¥å£®çš„å‚æ•°å¤„ç†å’Œå¼•å·
        wrapper_content = f'''#!/bin/sh
# APK wrapper script to fix dependency format issues (v2)
REAL_APK="{apk_real_path}"

# Log wrapper execution for debugging
# echo "APK Wrapper executing with args: $@" >> /tmp/apk_wrapper.log

if [ "$1" = "mkpkg" ]; then
    fixed_args=""
    skip_next=0
    depend_fixed=0

    # Iterate through arguments carefully
    for arg in "$@"; do
        if [ "$skip_next" -eq 1 ]; then
            skip_next=0
            continue
        fi

        case "$arg" in
            --info)
                # Check the next argument
                next_arg=$(eval echo \\$\\$\\(\\( \\(echo "$@" | awk -v current="$arg" '{{ for(i=1; i<=NF; i++) if ($i == current) print i+1 }}'\\) \\)\\))
                # echo "Next arg for --info: $next_arg" >> /tmp/apk_wrapper.log # Debug log
                if echo "$next_arg" | grep -q "^depends:"; then
                    # Extract dependencies, handling potential spaces within quotes
                    deps_raw=$(echo "$next_arg" | sed 's/^depends://')
                    # echo "Raw deps: $deps_raw" >> /tmp/apk_wrapper.log # Debug log

                    # Clean dependencies: remove version constraints, remove duplicates, handle empty strings
                    # Use awk for more robust splitting on spaces, then process each part
                    fixed_deps=$(echo "$deps_raw" | awk '{{for(i=1;i<=NF;i++) print $i}}' | sed -e 's/[<>=!~].*//g' -e '/^$/d' | sort -u | tr '\\n' ' ' | sed 's/ $//')
                    # echo "Fixed deps: $fixed_deps" >> /tmp/apk_wrapper.log # Debug log

                    # Reconstruct the argument with proper quoting
                    fixed_args="$fixed_args --info 'depends:$fixed_deps'" # Use single quotes for the value
                    skip_next=1 # Skip the original dependency string in the next iteration
                    depend_fixed=1
                else
                    # Not a depends info, pass both args as they are
                    fixed_args="$fixed_args '$arg' '$next_arg'" # Quote both
                    skip_next=1
                fi
                ;;
            *)
                # Handle other arguments, quote them just in case
                fixed_args="$fixed_args '$arg'"
                ;;
        esac
    done

    if [ "$depend_fixed" -eq 1 ]; then
        echo "ğŸ”§ APK wrapper: Fixed dependency format for mkpkg" >&2
        # echo "Executing: $REAL_APK $fixed_args" >> /tmp/apk_wrapper.log # Debug log
        eval "$REAL_APK $fixed_args" # Use eval to handle the constructed args string
        exit $? # Propagate exit code
    else
        # echo "Executing original: $REAL_APK $@" >> /tmp/apk_wrapper.log # Debug log
        "$REAL_APK" "$@"
        exit $?
    fi
else
    # Not mkpkg, just pass through
    # echo "Executing original (non-mkpkg): $REAL_APK $@" >> /tmp/apk_wrapper.log # Debug log
    "$REAL_APK" "$@"
    exit $?
fi
'''
        with open(apk_script_path, 'w') as f:
            f.write(wrapper_content)
        os.chmod(apk_script_path, 0o755)
        print("âœ… å·²åˆ›å»º APK å‘½ä»¤åŒ…è£…å™¨ (wrapper)ã€‚")
        return True
    except Exception as e:
        print(f"âŒ åˆ›å»º APK å‘½ä»¤åŒ…è£…å™¨æ—¶å‡ºé”™: {e}")
        # å°è¯•æ¢å¤
        if os.path.exists(apk_real_path) and not os.path.exists(apk_script_path):
            try:
                print(f"â„¹ï¸ å°è¯•æ¢å¤åŸå§‹ apk ä» {apk_real_path}")
                shutil.move(apk_real_path, apk_script_path)
            except Exception as re_e:
                 print(f"âš ï¸ æ¢å¤åŸå§‹ apk å¤±è´¥: {re_e}")
        return False


def fix_luci_lib_taskd_extra_depends():
    """ä¸“é—¨æ³¨é‡Šæ‰ luci-lib-taskd/Makefile ä¸­çš„ LUCI_EXTRA_DEPENDS è¡Œ"""
    print("ğŸ”§ å°è¯•ç‰¹å®šä¿®å¤: æ³¨é‡Šæ‰ luci-lib-taskd/Makefile ä¸­çš„ LUCI_EXTRA_DEPENDS...")
    makefile_path = None
    # ç²¾ç¡®æŸ¥æ‰¾ Makefile
    possible_paths = list(Path(".").glob("**/feeds/small8/luci-lib-taskd/Makefile"))
    if not possible_paths:
         possible_paths = list(Path(".").glob("**/package/feeds/small8/luci-lib-taskd/Makefile")) # å¤‡ç”¨

    if not possible_paths:
        print(f"  âš ï¸ æœªæ‰¾åˆ° luci-lib-taskd çš„ Makefileã€‚")
        return False
    makefile_path = possible_paths[0]
    print(f"  â¡ï¸ å®šä½åˆ° Makefile: {makefile_path}")

    try:
        with open(makefile_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        new_lines = []
        modified = False
        found_target_line = False

        # ç²¾ç¡®åŒ¹é…éœ€è¦æ³¨é‡Šæ‰çš„è¡Œ
        target_line_pattern = re.compile(r"^\s*LUCI_EXTRA_DEPENDS\s*:=\s*taskd\s*\(\s*>=?\s*[\d.-]+\s*\)\s*$", re.IGNORECASE)

        for i, line in enumerate(lines):
            stripped_line = line.strip()
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç›®æ ‡è¡Œä¸”æœªè¢«æ³¨é‡Š
            if target_line_pattern.match(stripped_line) and not stripped_line.startswith("#"):
                found_target_line = True
                print(f"  ğŸ”§ åœ¨è¡Œ {i+1} æ³¨é‡Šæ‰: {line.strip()}")
                new_lines.append("#" + line) # åœ¨è¡Œé¦–æ·»åŠ  #
                modified = True
            # æ£€æŸ¥æ˜¯å¦å·²ç»æ˜¯è¢«æ³¨é‡Šçš„ç›®æ ‡è¡Œ
            elif stripped_line.startswith("#") and target_line_pattern.match(stripped_line.lstrip("#").strip()):
                 found_target_line = True
                 print(f"  â„¹ï¸ åœ¨è¡Œ {i+1} å‘ç°å·²æ³¨é‡Šçš„ç›®æ ‡è¡Œ: {line.strip()}")
                 new_lines.append(line) # ä¿æŒæ³¨é‡ŠçŠ¶æ€
            else:
                new_lines.append(line)

        if not found_target_line:
             print(f"  âš ï¸ æœªæ‰¾åˆ°éœ€è¦æ³¨é‡Šçš„ LUCI_EXTRA_DEPENDS è¡Œã€‚")
             # æ£€æŸ¥ DEPENDS æ˜¯å¦å·²è¢«æ‰‹åŠ¨ä¿®å¤ï¼ˆä½œä¸ºåå¤‡æ£€æŸ¥ï¼‰
             define_block_pattern = re.compile(r'define Package/luci-lib-taskd\s*.*?\s*DEPENDS\s*:=\s*\+taskd\s+\+luci-lib-xterm\s+\+luci-lua-runtime(?:\s+\+libc)?\s*.*?\s*endef', re.DOTALL | re.IGNORECASE)
             if define_block_pattern.search("".join(lines)):
                 print("  â„¹ï¸ æ£€æµ‹åˆ°å¯èƒ½å·²è¢«æ‰‹åŠ¨ä¿®å¤çš„ DEPENDS å®šä¹‰ã€‚")
                 return True # è®¤ä¸ºé—®é¢˜å·²è§£å†³
             return False # ç¡®å®æ²¡æ‰¾åˆ°é—®é¢˜è¡Œ

        if modified:
            print(f"  âœ… å‡†å¤‡å†™å›ä¿®æ”¹åˆ° {makefile_path}")
            with open(makefile_path, 'w', encoding='utf-8') as f:
                f.writelines(new_lines)
            # æ¸…ç†è¯¥åŒ…çš„ç¼“å­˜
            print(f"  ğŸ§¹ æ¸…ç†åŒ… 'luci-lib-taskd' ç¼“å­˜ (DIRCLEAN)...")
            subprocess.run(["make", f"DIRCLEAN=1", f"{makefile_path.parent}/clean"], check=False, capture_output=True)
            # æ¸…ç† tmp ç›®å½•å¯èƒ½æœ‰åŠ©äºç¡®ä¿æ›´æ”¹ç”Ÿæ•ˆ
            print("  ğŸ§¹ æ¸…ç† tmp ç›®å½•...")
            if os.path.exists("tmp"):
                try: shutil.rmtree("tmp"); print("    âœ… tmp ç›®å½•å·²åˆ é™¤ã€‚")
                except Exception as e: print(f"    âš ï¸ æ¸…ç† tmp ç›®å½•å¤±è´¥: {e}")
            return True
        else:
            print(f"  â„¹ï¸ {makefile_path} æ— éœ€ä¿®æ”¹ (LUCI_EXTRA_DEPENDS å·²æ³¨é‡Šæˆ–ä¸å­˜åœ¨)ã€‚")
            return True # è®¤ä¸ºé—®é¢˜å·²è§£å†³æˆ–æ— éœ€å¤„ç†

    except Exception as e:
        print(f"âŒ ä¿®æ”¹åŒ… 'luci-lib-taskd' çš„ Makefile æ—¶å‡ºé”™: {e}")
        return False

# --- æ›´æ–° fix_apk_depends_problem ---
def fix_apk_depends_problem():
    """ç»¼åˆæ€§è§£å†³æ–¹æ¡ˆè§£å†³ APK ä¾èµ–æ ¼å¼é—®é¢˜ (v8 - ä¼˜å…ˆä¿®å¤ç‰¹å®šåŒ… Makefile é—®é¢˜)"""
    print("ğŸ” å°è¯•ç»¼åˆè§£å†³æ–¹æ¡ˆä¿®å¤ APK ä¾èµ–æ ¼å¼é—®é¢˜...")
    fixed_something = False

    # æ­¥éª¤ 1: ä¸“é—¨ä¿®å¤ luci-lib-taskd çš„ LUCI_EXTRA_DEPENDS
    print("  æ–¹æ³• 1: å°è¯•æ³¨é‡Šæ‰ luci-lib-taskd/Makefile ä¸­çš„ LUCI_EXTRA_DEPENDS...")
    if fix_luci_lib_taskd_extra_depends():
        print("  âœ… æ–¹æ³• 1 (æ³¨é‡Š LUCI_EXTRA_DEPENDS) æ‰§è¡Œå®Œæˆã€‚")
        fixed_something = True
    else:
        print("  â„¹ï¸ æ–¹æ³• 1 (æ³¨é‡Š LUCI_EXTRA_DEPENDS) æœªè¿›è¡Œä¿®æ”¹æˆ–å¤±è´¥ã€‚")

    # æ­¥éª¤ 2: å¦‚æœä¸Šä¸€æ­¥æ— æ•ˆï¼Œå†å°è¯•ä¿®æ”¹ luci.mk (ä½œä¸ºåå¤‡)
    if not fixed_something:
        print("  æ–¹æ³• 2: å°è¯•ç›´æ¥ä¿®æ”¹ luci.mk ä¸­çš„ apk mkpkg è°ƒç”¨...")
        if fix_apk_directly():
            print("  âœ… æ–¹æ³• 2 (ä¿®æ”¹ luci.mk) æ‰§è¡Œå®Œæˆã€‚")
            fixed_something = True
        else:
            print("  âŒ æ–¹æ³• 2 (ä¿®æ”¹ luci.mk) å¤±è´¥ã€‚")

    # æ­¥éª¤ 3: å°è¯•ä¿®å¤å…·ä½“åŒ…çš„ DEPENDS:= è¡Œ (ä½œä¸ºè¡¥å……)
    # è¿™ä¸ªæ­¥éª¤ç°åœ¨å¯èƒ½ä¸å¤ªå¿…è¦ï¼Œå› ä¸ºæ ¹æºæ˜¯ LUCI_EXTRA_DEPENDSï¼Œä½†ä¿ç•™ä»¥é˜²ä¸‡ä¸€
    apk_error_sig = get_error_signature(log_content_global)
    if "apk_depends_invalid" in apk_error_sig:
        failed_pkg_name = apk_error_sig.split(":")[-1]
        if failed_pkg_name != "unknown_pkg_from_apk":
            print(f"  è¡¥å……æ–¹æ³•: å°è¯•ä¿®å¤åŒ… '{failed_pkg_name}' çš„ Makefile DEPENDS...")
            # ... (æŸ¥æ‰¾å¹¶ä¿®å¤å…·ä½“åŒ… Makefile çš„é€»è¾‘) ...
            pass # å¯ä»¥æš‚æ—¶è·³è¿‡æˆ–ä¿ç•™ä¹‹å‰çš„é€»è¾‘


    return fixed_something
def fix_apk_wrapper_syntax():
    """ä¿®å¤ APK åŒ…è£…å™¨è„šæœ¬ä¸­çš„è¯­æ³•é”™è¯¯"""
    print("ğŸ”§ æ£€æµ‹åˆ° APK wrapper è¯­æ³•é”™è¯¯ï¼Œå°è¯•ä¿®å¤...")

    wrapper_path = Path("staging_dir/host/bin/apk")
    real_path = Path("staging_dir/host/bin/apk.real")

    if wrapper_path.exists() and real_path.exists():
        try:
            # è¯»å–å½“å‰çš„åŒ…è£…å™¨è„šæœ¬
            with open(wrapper_path, 'r') as f:
                content = f.read()

            # æ£€æŸ¥æ˜¯å¦æ˜¯æˆ‘ä»¬çš„ wrapper (é€šè¿‡æ³¨é‡Šåˆ¤æ–­)
            if "# APK wrapper script" in content:
                print("  â„¹ï¸ æ£€æµ‹åˆ°æ—§çš„ APK wrapperï¼Œç§»é™¤å¹¶æ¢å¤åŸå§‹å‘½ä»¤...")
                wrapper_path.unlink() # åˆ é™¤è„šæœ¬
                real_path.rename(wrapper_path) # æ¢å¤åŸå§‹å‘½ä»¤
                wrapper_path.chmod(0o755) # æ¢å¤æƒé™
                print("  âœ… å·²æ¢å¤åŸå§‹ APK å‘½ä»¤ã€‚")

                # æ¢å¤åï¼Œå°è¯•ç›´æ¥ä¿®å¤ä¾èµ–é—®é¢˜ï¼Œå› ä¸ºè¿™å¯èƒ½æ˜¯æ ¹æœ¬åŸå› 
                print("  â–¶ï¸ å°è¯•å†æ¬¡è¿è¡Œç›´æ¥ä¿®å¤ (luci.mk)...")
                return fix_apk_directly() # è¿”å›ç›´æ¥ä¿®å¤çš„ç»“æœ
            else:
                print(f"  âš ï¸ {wrapper_path} å­˜åœ¨ä½†ä¸æ˜¯é¢„æœŸçš„ wrapper è„šæœ¬ã€‚")
                # å¯èƒ½æ˜¯å…¶ä»–ä¸œè¥¿ï¼Œä¸è¦åŠ¨å®ƒï¼Œè¿”å› False
                return False
        except Exception as e:
            print(f"âŒ ç§»é™¤æ—§ wrapper æˆ–æ¢å¤åŸå§‹ apk æ—¶å‡ºé”™: {e}")
            return False
    elif wrapper_path.exists() and not real_path.exists():
         print(f"  âš ï¸ æ‰¾åˆ° {wrapper_path} ä½†æ²¡æœ‰å¤‡ä»½ {real_path}ã€‚å¯èƒ½æ˜¯åŸå§‹ apkã€‚")
         # å‡è®¾å®ƒæ˜¯åŸå§‹apkï¼Œå°è¯•ç›´æ¥ä¿®å¤
         print("  â–¶ï¸ å°è¯•è¿è¡Œç›´æ¥ä¿®å¤ (luci.mk)...")
         return fix_apk_directly()
    else:
        print(f"  âš ï¸ æ‰¾ä¸åˆ° APK wrapper ({wrapper_path}) æˆ–åŸå§‹å¤‡ä»½ ({real_path})ã€‚")
        # å°è¯•ç›´æ¥ä¿®å¤
        print("  â–¶ï¸ å°è¯•è¿è¡Œç›´æ¥ä¿®å¤ (luci.mk)...")
        return fix_apk_directly()


def get_error_signature(log_content):
    """ä»æ—¥å¿—å†…å®¹ä¸­æå–ä¸€ä¸ªæ›´å‡†ç¡®çš„é”™è¯¯ç­¾å (v3)"""
    if not log_content: return "no_log_content"
    apk_add_invalid_format_match = re.search(
        r"ERROR: ('([^=]+)=' is not a valid world dependency).*?make\[\d+\]: \*\*\* .*?package/install.* Error 99",
        log_content, re.DOTALL
    )
    if apk_add_invalid_format_match:
        invalid_package = apk_add_invalid_format_match.group(2)
        # Ensure absolute path isn't captured if present in some logs
        invalid_package = os.path.basename(invalid_package)
        return f"apk_add_invalid_dep_format:{invalid_package}"
    if apk_error_match:
        pkg_name = apk_error_match.group(2)
        # Avoid confusion with the new signature if it's base-files failing here (less likely)
        if pkg_name != "base-files":
             return f"apk_depends_invalid:{pkg_name}"

    # 2. Makefile ä¾èµ–ç¼ºå¤±è­¦å‘Š (å–ç¬¬ä¸€ä¸ªä½œä¸ºä»£è¡¨)
    dep_warning_match = re.search(r"WARNING: Makefile '([^']+)' has a dependency on '([^']*)', which does not exist", log_content)
    if dep_warning_match:
        # ... (existing logic for dep_warning_match) ...
        # Check if the real error was already identified
        if apk_add_invalid_format_match: # Don't let warning override the real error
             pass # Ignore this warning if the apk_add error was found
        else:
             # ... (extract pkg_name and bad_dep as before) ...
             if bad_dep and bad_dep.lower() not in ['perl_tests', ''] and not bad_dep.startswith(('p,', '(virtual)', '$')):
                 return f"makefile_dep_missing:{pkg_name}:{bad_dep}"
    # 3. APK Wrapper è¯­æ³•é”™è¯¯
    if "Syntax error:" in log_content and "bin/apk" in log_content:
         return "apk_wrapper_syntax"

    # 4. Netifd é“¾æ¥é”™è¯¯
    if "undefined reference to" in log_content and re.search(r'netifd|toolchain.*netifd', log_content):
        # ... (ä¿æŒä¹‹å‰çš„ netifd ç­¾åé€»è¾‘) ...
        ref_match = re.search(r"undefined reference to `([^']+)'", log_content)
        ref = ref_match.group(1) if ref_match else "unknown_symbol"
        if "netifd" in log_content: # ç®€å•æ£€æŸ¥
             return f"netifd_link_error:{ref}"


    # 5. Makefile åˆ†éš”ç¬¦é”™è¯¯
    if "missing separator" in log_content and ("Stop." in log_content or "***" in log_content):
         # ... (ä¿æŒä¹‹å‰çš„ separator ç­¾åé€»è¾‘) ...
         makefile_match = re.search(r'^([^:]+):\d+: \*\*\* missing separator', log_content, re.MULTILINE)
         makefile = makefile_match.group(1) if makefile_match else "unknown_makefile"
         return f"makefile_separator:{makefile}"

    # 6. Patch å¤±è´¥
    if ("Patch failed" in log_content or "Only garbage was found" in log_content or "unexpected end of file in patch" in log_content):
         # ... (ä¿æŒä¹‹å‰çš„ patch ç­¾åé€»è¾‘) ...
         patch_match = re.search(r'Applying (.+\.patch)', log_content)
         patch = os.path.basename(patch_match.group(1)) if patch_match else "unknown_patch"
         pkg_match = re.search(r"make\[\d+\]: Entering directory .*?/([^/']+)", log_content)
         pkg_name = pkg_match.group(1) if pkg_match else "unknown_pkg"
         return f"patch_failed:{pkg_name}:{patch}"


    # 7. Lua Neturl ä¸‹è½½é”™è¯¯
    if LIBS_AVAILABLE and 'lua-neturl' in log_content and ('Download failed' in log_content or 'Hash mismatch' in log_content or 'No more mirrors to try' in log_content):
        return "lua_neturl_download"

    # 8. Trojan Plus é”™è¯¯
    if 'trojan-plus' in log_content and 'buffer-cast' in log_content:
        return "trojan_plus_buffer_cast"

    # 9. é€šç”¨æ„å»ºå¤±è´¥ (æå–åŒ…å)
    generic_fail_match = re.search(r"ERROR: package/(?:feeds/[^/]+/|pkgs/|libs/|utils/|network/|)?([^/]+) failed to build", log_content)
    if generic_fail_match:
        return f"generic_build_fail:{generic_fail_match.group(1)}" # group(1) æ˜¯åŒ…å

    # 10. é€šç”¨é”™è¯¯ä¿¡æ¯ (æå–å…³é”®å­—å’Œä¸Šä¸‹æ–‡)
    generic_error_match = re.search(r'(error:|failed|fatal error:|collect2: error: ld returned 1 exit status)', log_content, re.IGNORECASE)
    if generic_error_match:
        # ... (ä¿æŒä¹‹å‰çš„é€šç”¨é”™è¯¯ç­¾åé€»è¾‘) ...
        error_keyword = generic_error_match.group(1).lower().split(':')[0]
        context_line = ""
        for line in reversed(log_content.splitlines()):
             if error_keyword in line.lower():
                 context_line = re.sub(r'\x1b\[[0-9;]*[mK]', '', line).strip()[:80]
                 break
        return f"generic_error:{error_keyword}:{context_line}"


    return "unknown_error"


import re
import subprocess
import shutil
from pathlib import Path
import os # Ensure os is imported

# Make sure get_relative_path is defined or imported if used here
# Assuming get_relative_path function exists as before

def get_error_signature(log_content):
    # Assuming get_error_signature function exists as before
    # Make sure it correctly returns "apk_add_invalid_dep_format:base-files"
    # For this specific log
    if not log_content: return "no_log_content"
    apk_add_invalid_format_match = re.search(
        r"ERROR: ('([^=]+)=' is not a valid world dependency).*?make\[\d+\]: \*\*\* .*?package/install.* Error 99",
        log_content, re.DOTALL
    )
    if apk_add_invalid_format_match:
        invalid_package = apk_add_invalid_format_match.group(2)
        # Ensure absolute path isn't captured if present in some logs
        invalid_package = os.path.basename(invalid_package)
        return f"apk_add_invalid_dep_format:{invalid_package}"
    # Add other signature detections here if needed
    return "unknown_error"


import re
import subprocess
import shutil
from pathlib import Path
import os

# Assuming get_relative_path function exists as before
# Assuming get_error_signature function exists and works as before

import re
import subprocess
import shutil
from pathlib import Path
import os

# Assuming get_relative_path function exists as before
# Assuming get_error_signature function exists and works as before
# --- Global flag for pre-computation ---
needs_base_files_precompute = False
def fix_apk_add_base_files_issue(log_content):
    """ä¿®å¤ apk add æ—¶ base-files= æˆ–ç±»ä¼¼åŒ…ç‰ˆæœ¬ç¼ºå¤±å¯¼è‡´çš„ Error 99 (v11: è®¾ç½®é¢„å¤„ç†æ ‡å¿—)"""
    global needs_base_files_precompute
    print("ğŸ”§ æ£€æµ‹åˆ° apk add æ— æ•ˆä¾èµ–æ ¼å¼é”™è¯¯ (é€šå¸¸ç”± base-files ç‰ˆæœ¬ç¼ºå¤±å¼•èµ·)ã€‚")
    print(f"  è®¾ç½®æ ‡å¿—ï¼Œåœ¨ä¸‹æ¬¡å°è¯•å‰é¢„å…ˆç¼–è¯‘ base-files å¹¶ä¿®å¤ç‰ˆæœ¬æ–‡ä»¶å...")

    action_taken = False

    # --- Perform minimal cleanup ---
    tmp_dir = Path("tmp")
    if tmp_dir.exists():
        print(f"  ğŸ§¹ æ¸…ç†ç›®å½•: {get_relative_path(str(tmp_dir))}")
        try:
            shutil.rmtree(tmp_dir)
            action_taken = True
        except Exception as e:
            print(f"    âš ï¸ æ¸…ç† {tmp_dir} ç›®å½•å¤±è´¥: {e}")
            action_taken = True # Still counts as an attempt
    # Ensure tmp exists for subsequent steps
    try:
        tmp_dir.mkdir(exist_ok=True)
    except Exception as e:
        print(f"    âš ï¸ åˆ›å»º {tmp_dir} ç›®å½•å¤±è´¥: {e}")

    # Clean staging package directory
    target_arch_match = re.search(r'staging_dir/target-([a-zA-Z0-9_]+)', log_content)
    package_dir_match = re.search(r'staging_dir/packages/([a-zA-Z0-9_]+)', log_content)
    staging_pkg_dir_path = None
    if package_dir_match:
        staging_pkg_dir_path = Path("staging_dir/packages") / package_dir_match.group(1)
    elif target_arch_match:
         target_name = target_arch_match.group(1)
         if 'ramips' in target_name:
             staging_pkg_dir_path = Path("staging_dir/packages/ramips")
    if staging_pkg_dir_path and staging_pkg_dir_path.exists():
        print(f"  ğŸ§¹ æ¸…ç†ç›®å½•: {get_relative_path(str(staging_pkg_dir_path))}")
        try:
            shutil.rmtree(staging_pkg_dir_path)
            action_taken = True
        except Exception as e:
            print(f"    âš ï¸ æ¸…ç† {staging_pkg_dir_path} ç›®å½•å¤±è´¥: {e}")
            action_taken = True

    # --- Set the flag ---
    needs_base_files_precompute = True
    print("  âœ… å·²è®¾ç½® base-files é¢„å¤„ç†æ ‡å¿—ã€‚")

    # Return True to indicate a fix strategy was determined
    return True
# ä¸»é€»è¾‘
def main():
    parser = argparse.ArgumentParser(description='OpenWrt ç¼–è¯‘ä¿®å¤è„šæœ¬')
    parser.add_argument('make_command', help='ç¼–è¯‘å‘½ä»¤ï¼Œå¦‚ "make V=s"')
    parser.add_argument('log_file', help='æ—¥å¿—æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--max-retry', type=int, default=8, help='æœ€å¤§é‡è¯•æ¬¡æ•°')
    parser.add_argument('--jobs', type=int, default=0, help='åˆå§‹å¹¶è¡Œä»»åŠ¡æ•°')
    args = parser.parse_args()

    base_cmd = re.sub(r'\s-j\s*\d+', '', args.make_command).strip()
    jobs = args.jobs if args.jobs > 0 else (os.cpu_count() or 1)
    retry = 1
    log_content_global = ""
    last_error = None
    same_error_count = 0

    while retry <= args.max_retry:
        cmd = f"{base_cmd} -j{jobs}"
        print(f"å°è¯• {retry}/{args.max_retry} æ¬¡: {cmd}")
        log_file = f"{Path(args.log_file).stem}.run.{retry}.log"
        
        process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)
        with open(log_file, 'w', encoding='utf-8') as f:
            for line in process.stdout:
                sys.stdout.write(line)
                f.write(line)
        status = process.wait()
        with open(log_file, 'r', encoding='utf-8') as f:
            log_content_global = f.read()

        if status == 0:
            print("ç¼–è¯‘æˆåŠŸï¼")
            return 0
        
        error = get_error_signature(log_content_global)
        print(f"é”™è¯¯: {error}")

        if error == last_error:
            same_error_count += 1
            if same_error_count >= 2:
                print("è¿ç»­ä¸¤æ¬¡ç›¸åŒé”™è¯¯ï¼Œåœæ­¢é‡è¯•")
                break
        else:
            same_error_count = 0

        last_error = error

        if error == "oom_detected":
			jobs = handle_oom(jobs, log_content_global)
		elif error == "netifd_link_error":
			fix_netifd_libnl_tiny()
		elif error == "lua_neturl_download":
			fix_lua_neturl_download(log_content_global)
		elif error == "trojan_plus_buffer_cast":
			fix_trojan_plus_issues()
		elif error == "patch_failed":
			fix_patch_application(log_content_global)
		elif error == "makefile_separator":
			fix_makefile_separator(log_content_global)
		elif error == "directory_conflict":
			fix_directory_conflict(log_content_global)
		elif error == "symlink_conflict":
			fix_symbolic_link_conflict(log_content_global)
		elif error == "toolchain_provides_syntax":
			fix_toolchain_provides_syntax(log_content_global)
		elif error == "luci_lib_taskd_depends":
			fix_luci_lib_taskd_extra_depends()
		elif error == "apk_add_base_files":
			fix_apk_add_base_files_issue(log_content_global)
		elif error == "makefile_dep_missing":
			fix_depends_format(log_content_global)
		elif error == "unknown_error":
			print("æœªçŸ¥é”™è¯¯ï¼Œæ— æ³•è‡ªåŠ¨ä¿®å¤")
		else:
			print(f"æœªå¤„ç†çš„é”™è¯¯ç±»å‹: {error}")

        retry += 1
        time.sleep(3 if error != "unknown_error" else 1)

    print("ç¼–è¯‘å¤±è´¥ï¼Œè¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°æˆ–è¿ç»­ç›¸åŒé”™è¯¯")
    return 1

if __name__ == "__main__":
    sys.exit(main())
